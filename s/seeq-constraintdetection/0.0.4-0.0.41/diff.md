# Comparing `tmp/seeq_constraintdetection-0.0.4-py3-none-any.whl.zip` & `tmp/seeq_constraintdetection-0.0.41-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,21 @@
-Zip file size: 55356 bytes, number of entries: 19
--rw-rw-rw-  2.0 fat    21837 b- defN 22-Sep-16 08:39 seeq/addons/constraintdetection/_SPy_functions.py
--rw-rw-rw-  2.0 fat      857 b- defN 22-Aug-26 07:08 seeq/addons/constraintdetection/__init__.py
--rw-rw-rw-  2.0 fat     6494 b- defN 22-Sep-29 06:08 seeq/addons/constraintdetection/__main__.py
--rw-rw-rw-  2.0 fat     3022 b- defN 22-Aug-26 07:40 seeq/addons/constraintdetection/_copy.py
--rw-rw-rw-  2.0 fat    26666 b- defN 22-Oct-04 10:07 seeq/addons/constraintdetection/_saturation_detection.py
--rw-rw-rw-  2.0 fat    38551 b- defN 22-Sep-21 07:55 seeq/addons/constraintdetection/_seeq_add_on.py
--rw-rw-rw-  2.0 fat       21 b- defN 22-Oct-04 10:08 seeq/addons/constraintdetection/_version.py
--rw-rw-rw-  2.0 fat      895 b- defN 22-Sep-29 05:46 seeq/addons/constraintdetection/deployment_notebook/constraint_detection_master.ipynb
--rw-rw-rw-  2.0 fat    24572 b- defN 22-Sep-08 07:14 seeq/addons/constraintdetection/deployment_notebook/thresholds.PNG
--rw-rw-rw-  2.0 fat      613 b- defN 22-Aug-26 06:32 seeq/addons/constraintdetection/utils/__init__.py
--rw-rw-rw-  2.0 fat      731 b- defN 22-Aug-26 06:14 seeq/addons/constraintdetection/utils/_common.py
--rw-rw-rw-  2.0 fat     1298 b- defN 22-Aug-26 06:21 seeq/addons/constraintdetection/utils/_permissions.py
--rw-rw-rw-  2.0 fat     7863 b- defN 22-Aug-26 06:21 seeq/addons/constraintdetection/utils/_sdl.py
--rw-rw-rw-  2.0 fat    11524 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     5086 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/METADATA
--rw-rw-rw-  2.0 fat      576 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/NOTICE
--rw-rw-rw-  2.0 fat       92 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        5 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1980 b- defN 22-Oct-04 10:11 seeq_constraintdetection-0.0.4.dist-info/RECORD
-19 files, 152683 bytes uncompressed, 51974 bytes compressed:  66.0%
+Zip file size: 55527 bytes, number of entries: 19
+-rw-r--r--  2.0 unx    21837 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/_SPy_functions.py
+-rw-r--r--  2.0 unx      845 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/__init__.py
+-rw-r--r--  2.0 unx     6513 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/__main__.py
+-rw-r--r--  2.0 unx     2953 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/_copy.py
+-rw-r--r--  2.0 unx    26085 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/_saturation_detection.py
+-rw-r--r--  2.0 unx    38551 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/_seeq_add_on.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/_version.py
+-rw-r--r--  2.0 unx      895 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/deployment_notebook/constraint_detection_master.ipynb
+-rw-r--r--  2.0 unx    24572 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/deployment_notebook/thresholds.PNG
+-rw-r--r--  2.0 unx      604 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/utils/__init__.py
+-rw-r--r--  2.0 unx      714 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/utils/_common.py
+-rw-r--r--  2.0 unx     1265 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/utils/_permissions.py
+-rw-r--r--  2.0 unx     7863 b- defN 23-Jan-23 01:20 seeq/addons/constraintdetection/utils/_sdl.py
+-rw-r--r--  2.0 unx    11324 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5580 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/METADATA
+-rw-r--r--  2.0 unx      566 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/NOTICE
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/WHEEL
+-rw-r--r--  2.0 unx        5 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1986 b- defN 23-Jul-20 13:26 seeq_constraintdetection-0.0.41.dist-info/RECORD
+19 files, 152272 bytes uncompressed, 52133 bytes compressed:  65.8%
```

## zipnote {}

```diff
@@ -33,26 +33,26 @@
 
 Filename: seeq/addons/constraintdetection/utils/_permissions.py
 Comment: 
 
 Filename: seeq/addons/constraintdetection/utils/_sdl.py
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/LICENSE
+Filename: seeq_constraintdetection-0.0.41.dist-info/LICENSE
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/METADATA
+Filename: seeq_constraintdetection-0.0.41.dist-info/METADATA
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/NOTICE
+Filename: seeq_constraintdetection-0.0.41.dist-info/NOTICE
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/WHEEL
+Filename: seeq_constraintdetection-0.0.41.dist-info/WHEEL
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/top_level.txt
+Filename: seeq_constraintdetection-0.0.41.dist-info/top_level.txt
 Comment: 
 
-Filename: seeq_constraintdetection-0.0.4.dist-info/RECORD
+Filename: seeq_constraintdetection-0.0.41.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## seeq/addons/constraintdetection/__init__.py

 * *Ordering differences only*

```diff
@@ -1,12 +1,12 @@
-from ._saturation_detection import saturation_detection, generate_metadata, generate_constraint_index_table, \
-    generate_short_gap_capsule
-from ._SPy_functions import get_start_end_display_range, get_start_end_display_range_from_ids, \
-    pull_signals_from_asset_tree, push_signals, push_metadata, OnlyPushWorksheetsPatch, saturation_treemap, patching
-from ._seeq_add_on import HamburgerMenu, ConstraintDetection
-from ._version import __version__
-from . import utils
-
-__all__ = ['__version__', 'saturation_detection', 'generate_metadata', 'generate_constraint_index_table',
-           'get_start_end_display_range', 'pull_signals_from_asset_tree', 'push_signals', 'push_metadata',
-           'OnlyPushWorksheetsPatch', 'saturation_treemap', 'patching', 'generate_short_gap_capsule', 'HamburgerMenu',
-           'ConstraintDetection', utils]
+from ._saturation_detection import saturation_detection, generate_metadata, generate_constraint_index_table, \
+    generate_short_gap_capsule
+from ._SPy_functions import get_start_end_display_range, get_start_end_display_range_from_ids, \
+    pull_signals_from_asset_tree, push_signals, push_metadata, OnlyPushWorksheetsPatch, saturation_treemap, patching
+from ._seeq_add_on import HamburgerMenu, ConstraintDetection
+from ._version import __version__
+from . import utils
+
+__all__ = ['__version__', 'saturation_detection', 'generate_metadata', 'generate_constraint_index_table',
+           'get_start_end_display_range', 'pull_signals_from_asset_tree', 'push_signals', 'push_metadata',
+           'OnlyPushWorksheetsPatch', 'saturation_treemap', 'patching', 'generate_short_gap_capsule', 'HamburgerMenu',
+           'ConstraintDetection', utils]
```

## seeq/addons/constraintdetection/__main__.py

```diff
@@ -1,146 +1,150 @@
-import os
-import sys
-import argparse
-import subprocess
-from getpass import getpass
-from urllib.parse import urlparse
-from seeq import sdk, spy
-from ._copy import copy
-from .utils import sanitize_sdl_url
-from .utils import get_datalab_project_id, addon_tool_management
-
-NB_EXTENSIONS = ['widgetsnbextension', 'ipyvuetify', 'ipyvue']
-DEPLOYMENT_FOLDER = 'deployment'
-DEPLOYMENT_NOTEBOOK = "constraint_detection_master.ipynb"
-
-def permissions_defaults(permissions_group: list, permissions_users: list):
-    if permissions_group is None:
-        permissions_group = ['Everyone']
-
-    if permissions_users is None:
-        permissions_users = []
-    return permissions_group, permissions_users
-
-
-def install_app(sdl_url_, *, sort_key=None, permissions_group: list = None, permissions_users: list = None):
-    """
-    Installs Constraint Detection as an Add-on Tool in Seeq Workbench
-
-    Parameters
-    ----------
-    sdl_url_: str
-        URL of the SDL container. E.g. https://my.seeq.com/data-lab/6AB49411-917E-44CC-BA19-5EE0F903100C/
-    sort_key: str, default None
-        A string, typically one character letter. The sort_key determines the order in which the Add-on Tools are
-        displayed in the tool panel
-    permissions_group: list
-        Names of the Seeq groups that will have access to each tool
-    permissions_users: list
-        Names of Seeq users that will have access to each tool
-    Returns
-    --------
-    -: None
-        Constraint Detection will appear as Add-on Tool(s) in Seeq Workbench
-    """
-
-    sdl_url_ = sanitize_sdl_url(sdl_url_)
-
-    if sort_key is None:
-        sort_key = 'a'
-
-    permissions_group, permissions_users = permissions_defaults(permissions_group, permissions_users)
-
-    add_on_details = dict(
-        name='Constraint Detection',
-        description="Detect constraints and saturation in control loop data",
-        iconClass="fa fa-th",
-        targetUrl=f'{sdl_url_}/apps/{DEPLOYMENT_FOLDER}/{DEPLOYMENT_NOTEBOOK}?'
-                  f'workbookId={{workbookId}}&worksheetId={{worksheetId}}&workstepId={{workstepId}}',
-        linkType="window",
-        windowDetails="toolbar=0,location=0,left=800,top=400,height=1000,width=1400",
-        sortKey=sort_key,
-        reuseWindow=True,
-        permissions=dict(groups=permissions_group,
-                         users=permissions_users)
-    )
-
-    copy(des_folder=DEPLOYMENT_FOLDER, src_folder='deployment_notebook',
-         overwrite_folder=False, overwrite_contents=True)
-    addon_tool_management(add_on_details)
-
-
-def install_nbextensions():
-    for extension in NB_EXTENSIONS:
-        subprocess.run(f'jupyter nbextension install --user --py {extension}', cwd=os.path.expanduser('~'), shell=True,
-                       check=True)
-        subprocess.run(f'jupyter nbextension enable --user --py {extension}', cwd=os.path.expanduser('~'), shell=True,
-                       check=True)
-
-
-def cli_interface():
-    """ Installs Constraint Detection as a Seeq Add-on Tool """
-    parser = argparse.ArgumentParser(description='Install Constraint Detection as a Seeq Add-on Tool')
-    parser.add_argument('--nbextensions_only', action='store_true',
-                        help='Only installs the nbextensions without installing or updating the Add-on Tools'
-                             'links')
-    parser.add_argument('--username', type=str,
-                        help='Username or Access Key of Seeq admin user installing the tool(s) ')
-    parser.add_argument('--seeq_url', type=str, nargs='?',
-                        help="Seeq hostname URL with the format https://my.seeq.com/ or https://my.seeq.com:34216")
-    parser.add_argument('--users', type=str, nargs='*', default=[],
-                        help="List of the Seeq users to will have access to the Constraint Detection Add-on Tool,"
-                             " default: %(default)s")
-    parser.add_argument('--groups', type=str, nargs='*', default=['Everyone'],
-                        help="List of the Seeq groups to will have access to the Constraint Detection Add-on Tool, "
-                             "default: %(default)s")
-    return parser.parse_args()
-
-
-if __name__ == '__main__':
-
-    args = cli_interface()
-
-    if args.nbextensions_only:
-        print("\n\nInstalling and enabling nbextensions")
-        install_nbextensions()
-        sys.exit(0)
-    user = args.username
-    if user is None:
-        user = input("\nAccess Key or Username: ")
-
-    passwd = getpass("Access Key Password: ")
-    spy.login(username=user, password=passwd, ignore_ssl_errors=True)
-    seeq_url = args.seeq_url
-    if seeq_url is None:
-        seeq_url = input(f"\n Seeq base URL [{spy.client.host.split('/api')[0]}]: ")
-        if seeq_url == '':
-            seeq_url = spy.client.host.split('/api')[0]
-    url_parsed = urlparse(seeq_url)
-    seeq_url_base = f"{url_parsed.scheme}://{url_parsed.netloc}"
-
-    project_id = spy.utils.get_data_lab_project_id()
-    sdl_url = f'{seeq_url_base}/data-lab/{project_id}'
-    if project_id is None:
-        print("\nThe project ID could not be found. Please provide the SDL project URL with the format "
-              "https://my.seeq.com/data-lab/6AB49411-917E-44CC-BA19-5EE0F903100C/\n")
-        sdl_url = input("Seeq Data Lab project URL: ")
-        project_id = get_datalab_project_id(sanitize_sdl_url(sdl_url), sdk.ItemsApi(spy.client))
-        if not project_id:
-            raise RuntimeError(f'Could not install {args.apps} because the SDL project ID could not be found')
-    sdl_url_sanitized = sanitize_sdl_url(sdl_url)
-
-    print(f"\nThe Constraint Detection Tool will be installed on the SDL notebook: {sdl_url_sanitized}\n"
-          f"If this is not your intent, you can quit the installation now ")
-    print('\n[enter] to continue or type "quit" to exit installation')
-    choice = None
-    while choice != '' and choice != 'quit':
-        choice = input()
-        if choice == '':
-            print("\n\nInstalling and enabling nbextensions")
-            install_nbextensions()
-            install_app(sdl_url_sanitized, permissions_group=args.groups, permissions_users=args.users)
-        elif choice == 'quit':
-            print("\nExited installation")
-        else:
-            print(f'\nCommand "{choice}" is not valid')
+import os
+import sys
+import argparse
+import subprocess
+from getpass import getpass
+from urllib.parse import urlparse
+from seeq import sdk, spy
+from ._copy import copy
+from .utils import sanitize_sdl_url
+from .utils import get_datalab_project_id, addon_tool_management
+
+NB_EXTENSIONS = ['widgetsnbextension', 'ipyvuetify', 'ipyvue']
+DEPLOYMENT_FOLDER = 'deployment'
+DEPLOYMENT_NOTEBOOK = "constraint_detection_master.ipynb"
+DEFAULT_GROUP = ['Everyone']
+DEFAULT_USERS = []
+
+def permissions_defaults(permissions_group: list, permissions_users: list):
+    if permissions_group is None:
+        permissions_group = ['Everyone']
+
+    if permissions_users is None:
+        permissions_users = []
+    return permissions_group, permissions_users
+
+
+def install_app(sdl_url_, *, sort_key=None, permissions_group: list = None, permissions_users: list = None):
+    """
+    Installs Constraint Detection as an Add-on Tool in Seeq Workbench
+
+    Parameters
+    ----------
+    sdl_url_: str
+        URL of the SDL container. E.g. https://my.seeq.com/data-lab/6AB49411-917E-44CC-BA19-5EE0F903100C/
+    sort_key: str, default None
+        A string, typically one character letter. The sort_key determines the order in which the Add-on Tools are
+        displayed in the tool panel
+    permissions_group: list
+        Names of the Seeq groups that will have access to each tool
+    permissions_users: list
+        Names of Seeq users that will have access to each tool
+    Returns
+    --------
+    -: None
+        Constraint Detection will appear as Add-on Tool(s) in Seeq Workbench
+    """
+
+    sdl_url_ = sanitize_sdl_url(sdl_url_)
+
+    if sort_key is None:
+        sort_key = 'c'
+
+    permissions_group = permissions_group if permissions_group else DEFAULT_GROUP
+    permissions_users = permissions_users if permissions_users else DEFAULT_USERS
+
+    add_on_details = {
+        "Name": 'Constraint Detection',
+        "Description": "Detect constraints and saturation in control loop time series data",
+        "Icon": "fa fa-th",
+        "Target URL": f'{sdl_url_}/apps/{DEPLOYMENT_FOLDER}/{DEPLOYMENT_NOTEBOOK}',
+        "Link Type": "window",
+        "Window Details": "toolbar=0,location=0,left=800,top=400,height=1000,width=1400",
+        "Sort Key": sort_key,
+        "Reuse Window": True,
+        "Groups": permissions_group,
+        "Users": permissions_users
+    }
+
+    copy(des_folder=DEPLOYMENT_FOLDER, src_folder='deployment_notebook',
+         overwrite_folder=False, overwrite_contents=True)
+    print(f'\nCopied the notebook used by the Add-on to {DEPLOYMENT_FOLDER}')
+
+    spy.addons.install(add_on_details, include_workbook_parameters=True, update_tool=True, update_permissions=True)
+
+
+def install_nbextensions():
+    for extension in NB_EXTENSIONS:
+        subprocess.run(f'jupyter nbextension install --user --py {extension}', cwd=os.path.expanduser('~'), shell=True,
+                       check=True)
+        subprocess.run(f'jupyter nbextension enable --user --py {extension}', cwd=os.path.expanduser('~'), shell=True,
+                       check=True)
+
+
+def cli_interface():
+    """ Installs Constraint Detection as a Seeq Add-on Tool """
+    parser = argparse.ArgumentParser(description='Install Constraint Detection as a Seeq Add-on Tool')
+    parser.add_argument('--nbextensions_only', action='store_true',
+                        help='Only installs the nbextensions without installing or updating the Add-on Tools'
+                             'links')
+    parser.add_argument('--username', type=str,
+                        help='Username or Access Key of Seeq admin user installing the tool(s) ')
+    parser.add_argument('--seeq_url', type=str, nargs='?',
+                        help="Seeq hostname URL with the format https://my.seeq.com/ or https://my.seeq.com:34216")
+    parser.add_argument('--users', type=str, nargs='*', default=[],
+                        help="List of the Seeq users to will have access to the Constraint Detection Add-on Tool,"
+                             " default: %(default)s")
+    parser.add_argument('--groups', type=str, nargs='*', default=['Everyone'],
+                        help="List of the Seeq groups to will have access to the Constraint Detection Add-on Tool, "
+                             "default: %(default)s")
+    return parser.parse_args()
+
+
+if __name__ == '__main__':
+
+    args = cli_interface()
+
+    if args.nbextensions_only:
+        print("\n\nInstalling and enabling nbextensions")
+        install_nbextensions()
+        sys.exit(0)
+    user = args.username
+    if user is None:
+        user = input("\nAccess Key or Username: ")
+
+    passwd = getpass("Access Key Password: ")
+    spy.login(username=user, password=passwd, ignore_ssl_errors=True)
+    seeq_url = args.seeq_url
+    if seeq_url is None:
+        seeq_url = input(f"\n Seeq base URL [{spy.client.host.split('/api')[0]}]: ")
+        if seeq_url == '':
+            seeq_url = spy.client.host.split('/api')[0]
+    url_parsed = urlparse(seeq_url)
+    seeq_url_base = f"{url_parsed.scheme}://{url_parsed.netloc}"
+
+    project_id = spy.utils.get_data_lab_project_id()
+    sdl_url = f'{seeq_url_base}/data-lab/{project_id}'
+    if project_id is None:
+        print("\nThe project ID could not be found. Please provide the SDL project URL with the format "
+              "https://my.seeq.com/data-lab/6AB49411-917E-44CC-BA19-5EE0F903100C/\n")
+        sdl_url = input("Seeq Data Lab project URL: ")
+        project_id = get_datalab_project_id(sanitize_sdl_url(sdl_url), sdk.ItemsApi(spy.client))
+        if not project_id:
+            raise RuntimeError(f'Could not install {args.apps} because the SDL project ID could not be found')
+    sdl_url_sanitized = sanitize_sdl_url(sdl_url)
+
+    print(f"\nThe Constraint Detection Tool will be installed on the SDL notebook: {sdl_url_sanitized}\n"
+          f"If this is not your intent, you can quit the installation now ")
+    print('\n[enter] to continue or type "quit" to exit installation')
+    choice = None
+    while choice != '' and choice != 'quit':
+        choice = input()
+        if choice == '':
+            print("\n\nInstalling and enabling nbextensions")
+            install_nbextensions()
+            install_app(sdl_url_sanitized, permissions_group=args.groups, permissions_users=args.users)
+        elif choice == 'quit':
+            print("\nExited installation")
+        else:
+            print(f'\nCommand "{choice}" is not valid')
             print('\n[enter] to continue the installation or type "quit" to exit installation')
```

## seeq/addons/constraintdetection/_copy.py

 * *Ordering differences only*

```diff
@@ -1,70 +1,70 @@
-import os
-from pathlib import Path
-from distutils import dir_util
-import shutil
-from .utils import validate_argument_types
-
-mps_dir = Path(__file__).resolve().parent
-
-
-def copy(des_folder=None, src_folder=None, *, overwrite_folder=False, overwrite_contents=False):
-    """
-    Copies the files on the src_folder to a des_folder in the current working directory.
-
-    Parameters
-    ----------
-    des_folder : str
-        The destination folder. By default it will be copied to a 'deployment_notebook' folder
-         in the current working directory.
-    src_folder : str
-        Name of the folder that contains the documentation to be copied
-    overwrite_folder : bool
-        If True, any existing files in the specified folder will be deleted before the documentation is copied in.
-    overwrite_contents : bool
-        If True, files in the specified folder will be overwriting if necessary when the documentation is copied in.
-    """
-
-    validate_argument_types([
-        (des_folder, 'folder', str),
-        (src_folder, 'overwrite', str),
-        (overwrite_folder, 'overwrite', bool),
-        (overwrite_contents, 'overwrite', bool),
-    ])
-    root_src_dir = os.path.dirname(__file__)
-    print(root_src_dir)
-
-    if not des_folder:
-        des_folder = 'deployment'
-    des_folder_path = Path.cwd().joinpath(des_folder)
-
-    if not src_folder:
-        src_folder = 'deployment_notebook'
-    src_folder_path = mps_dir.joinpath(src_folder)
-
-    if des_folder_path.exists():
-        if not overwrite_folder and not overwrite_contents:
-            raise RuntimeError(
-                f"The {des_folder_path} directory already exists. If you would like to overwrite it, supply the "
-                f"overwrite_folder=True parameter to clean up the folder or overwrite_contents=True to keep the "
-                f"current files but overwrite them with the contents of {src_folder_path}. ")
-        if overwrite_folder:
-            dir_util.remove_tree(str(des_folder_path))
-            dir_util.copy_tree(src_folder_path, str(des_folder_path))
-            print(f'Copied MPS notebook to {des_folder_path}')
-        if overwrite_contents:
-            if not os.path.exists(des_folder_path):
-                os.makedirs(des_folder_path)
-            for src_dir, dirs, files in os.walk(src_folder_path):
-                for file_ in files:
-                    src_file = os.path.join(src_dir, file_)
-                    dst_file = os.path.join(des_folder_path, file_)
-                    if os.path.exists(dst_file):
-                        # in case of the src and dst are the same file
-                        if os.path.samefile(src_file, dst_file):
-                            continue
-                        os.remove(dst_file)
-                    shutil.copy(src_file, des_folder_path)
-
-    else:
-        dir_util.copy_tree(src_folder_path, str(des_folder_path))
+import os
+from pathlib import Path
+from distutils import dir_util
+import shutil
+from .utils import validate_argument_types
+
+mps_dir = Path(__file__).resolve().parent
+
+
+def copy(des_folder=None, src_folder=None, *, overwrite_folder=False, overwrite_contents=False):
+    """
+    Copies the files on the src_folder to a des_folder in the current working directory.
+
+    Parameters
+    ----------
+    des_folder : str
+        The destination folder. By default it will be copied to a 'deployment_notebook' folder
+         in the current working directory.
+    src_folder : str
+        Name of the folder that contains the documentation to be copied
+    overwrite_folder : bool
+        If True, any existing files in the specified folder will be deleted before the documentation is copied in.
+    overwrite_contents : bool
+        If True, files in the specified folder will be overwriting if necessary when the documentation is copied in.
+    """
+
+    validate_argument_types([
+        (des_folder, 'folder', str),
+        (src_folder, 'overwrite', str),
+        (overwrite_folder, 'overwrite', bool),
+        (overwrite_contents, 'overwrite', bool),
+    ])
+    root_src_dir = os.path.dirname(__file__)
+    print(root_src_dir)
+
+    if not des_folder:
+        des_folder = 'deployment'
+    des_folder_path = Path.cwd().joinpath(des_folder)
+
+    if not src_folder:
+        src_folder = 'deployment_notebook'
+    src_folder_path = mps_dir.joinpath(src_folder)
+
+    if des_folder_path.exists():
+        if not overwrite_folder and not overwrite_contents:
+            raise RuntimeError(
+                f"The {des_folder_path} directory already exists. If you would like to overwrite it, supply the "
+                f"overwrite_folder=True parameter to clean up the folder or overwrite_contents=True to keep the "
+                f"current files but overwrite them with the contents of {src_folder_path}. ")
+        if overwrite_folder:
+            dir_util.remove_tree(str(des_folder_path))
+            dir_util.copy_tree(src_folder_path, str(des_folder_path))
+            print(f'Copied MPS notebook to {des_folder_path}')
+        if overwrite_contents:
+            if not os.path.exists(des_folder_path):
+                os.makedirs(des_folder_path)
+            for src_dir, dirs, files in os.walk(src_folder_path):
+                for file_ in files:
+                    src_file = os.path.join(src_dir, file_)
+                    dst_file = os.path.join(des_folder_path, file_)
+                    if os.path.exists(dst_file):
+                        # in case of the src and dst are the same file
+                        if os.path.samefile(src_file, dst_file):
+                            continue
+                        os.remove(dst_file)
+                    shutil.copy(src_file, des_folder_path)
+
+    else:
+        dir_util.copy_tree(src_folder_path, str(des_folder_path))
         print(f'Copied Constraint Detection notebook to {des_folder_path}')
```

## seeq/addons/constraintdetection/_saturation_detection.py

 * *Ordering differences only*

```diff
@@ -1,581 +1,581 @@
-import pandas as pd
-import numpy as np
-
-
-def generate_short_gap_capsule(short_gap_number, short_gap_unit, short_capsule_number, short_capsule_unit):
-    """
-    This function creates string that specify the short gaps and capsules for the High/Medium Constraint Conditions.
-
-    Parameters
-    ----------
-    short_gap_number: int
-        Integer which specifies the length of the gaps that should be closed in the High/Medium Contraint Conditions
-    short_gap_unit: str
-        Unit (seconds. minutes, hours) of the short gaps
-    short_capsule_number: int
-        Integer which specifies the length of the capsules that should be ignored in the High/Medium Contraint
-        Conditions
-    short_capsule_unit: str
-        Unit (seconds. minutes, hours) of the short capsules
-
-    Returns
-    -------
-    short_gap: str
-        String that contains the length and unit of the short gaps e.g. '2min'
-    short_capsule: str
-        String that contains the length and unit of the short capsules e.g. '2min'
-    """
-    if short_gap_unit == 'second(s)':
-        short_gap = str(short_gap_number) + 's'
-    elif short_gap_unit == 'minute(s)':
-        short_gap = str(short_gap_number) + 'min'
-    elif short_gap_unit == 'hour(s)':
-        short_gap = str(short_gap_number) + 'h'
-
-    if short_capsule_number == 0:
-        short_capsule = str(0.1) + 's'
-    if short_capsule_number > 0:
-        if short_capsule_unit == 'second(s)':
-            short_capsule = str(short_capsule_number) + 's'
-        elif short_capsule_unit == 'minute(s)':
-            short_capsule = str(short_capsule_number) + 'min'
-        elif short_capsule_unit == 'hour(s)':
-            short_capsule = str(short_capsule_number) + 'h'
-
-    return short_gap, short_capsule
-
-
-def saturation_detection(pulled_signals_df, checkbox_op, checkbox_pv, checkbox_sp, checkbox_mv, lower_threshold,
-                         upper_threshold, short_gap_number, short_gap_unit, short_capsule_number, short_capsule_unit):
-    """
-    This function analyzes every signal in the pulled_signals_df for saturation/constraints and adds the saturation
-    signal to the saturation_signals_df and the saturation/constraint index to the saturation_index_df.
-
-    Parameters
-    ----------
-    pulled_signals_df: pd.DataFrame
-        The dataframe with all signals in the original asset tree
-    checkbox_op: bool
-        True if OP checkbox is checked. False if OP checkbox is not checked.
-    checkbox_pv: bool
-        True if PV checkbox is checked. False if PV checkbox is not checked.
-    checkbox_sp: bool
-        True if SP checkbox is checked. False if SP checkbox is not checked.
-    checkbox_mv: bool
-        True if MV checkbox is checked. False if MV checkbox is not checked.
-    lower_threshold: float
-        The threshold which is used to set the yellow priority colour in treemap and to create the Medium Constraint
-        Condition.
-    upper_threshold: float
-        The threshold which is used to set the red priority colour in treemap and to create the High Constraint
-        Condition.
-    short_gap_number: int
-        Integer which specifies the length of the gaps that should be closed
-    short_gap_unit: str
-        Unit (seconds. minutes, hours) of the short gaps
-    short_capsule_number:int
-        Integer which specifies the length of the capsule that should be ignored
-    short_capsule_unit: str
-        Unit (seconds. minutes, hours) of the short capsules
-
-    Returns
-    -------
-    saturation_signals_df: pd.DataFrame
-        The dataframe which contains all saturation signals.
-    saturation_index_df: pd.DataFrame
-        The dataframe which contains signal name and contraint index
-    """
-    signals_for_analysis = []
-    if checkbox_op:
-        signals_for_analysis = signals_for_analysis + ['Controller Output']
-    if checkbox_pv:
-        signals_for_analysis = signals_for_analysis + ['Process Variable']
-    if checkbox_sp:
-        signals_for_analysis = signals_for_analysis + ['Setpoint']
-    if checkbox_mv:
-        signals_for_analysis = signals_for_analysis + ['Manipulated Variable']
-
-    if short_capsule_number == 0:
-        short_capsule = 0
-    elif short_capsule_number > 0:
-        if short_capsule_unit == 'second(s)':
-            short_capsule = short_capsule_number
-        elif short_capsule_unit == 'minute(s)':
-            short_capsule = short_capsule_number * 60
-        elif short_capsule_unit == 'hour(s)':
-            short_capsule = short_capsule_number * 60 * 60
-
-    if short_gap_number == 0:
-        short_gap = 0
-    elif short_gap_number > 0:
-        if short_gap_unit == 'second(s)':
-            short_gap = short_gap_number
-        elif short_gap_unit == 'minute(s)':
-            short_gap = short_gap_number * 60
-        elif short_gap_unit == 'hour(s)':
-            short_gap = short_gap_number * 60 * 60
-
-    # initiate empty dataframe for saturation signals saturation/constraint index
-    saturation_signals_df = pd.DataFrame()
-    saturation_index_df = pd.DataFrame(columns=['Signal Name and Path', 'Signal', 'Path', 'Index'])
-
-    # extended period of saturation: at least 3 consecutive samples have to be saturated to detect saturation
-    ext_length = 3
-
-    # Loop goes through all signals in the pull_data dataframe
-    for x in range(len(pulled_signals_df.columns)):
-
-        if 'Mode' in pulled_signals_df.columns[x]:
-            # auto manual mode data should not be analysed by the saturation detection
-            # mode columns are skipped and the loop starts with the next column
-            continue
-
-        if 'Controller Output' in pulled_signals_df.columns[x]:
-            if 'Controller Output' in signals_for_analysis:
-                pass
-            else:
-                continue
-
-        if 'Process Variable' in pulled_signals_df.columns[x]:
-            if 'Process Variable' in signals_for_analysis:
-                pass
-            else:
-                continue
-
-        if 'Setpoint' in pulled_signals_df.columns[x]:
-            if 'Setpoint' in signals_for_analysis:
-                pass
-            else:
-                continue
-
-        if 'Manipulated Variable' in pulled_signals_df.columns[x]:
-            if 'Manipulated Variable' in signals_for_analysis:
-                pass
-            else:
-                continue
-
-        if 'Process Variable' not in pulled_signals_df.columns[x] and 'Controller Output' not in \
-                pulled_signals_df.columns[x] and 'Setpoint' not in pulled_signals_df.columns[
-            x] and 'Manipulated Variable' not in pulled_signals_df.columns[x] and 'Mode' not in \
-                pulled_signals_df.columns[x]:
-            raise RuntimeError(
-                f'''Check if your asset tree has the required layout. Accepted signal names are "Controller Output", 
-                "Process Variable", "Setpoint", "Manipulated Variable" and "Mode". See User Guide for more 
-                information on the required layout''')
-
-            # format the current column as a numpy array
-        df_column = np.asarray(pulled_signals_df.iloc[:, x])
-        # get length of the column
-        df_column_length = len(df_column)
-        # calculate derivative of the column data
-        df_column_derivative = np.gradient(df_column)
-
-        # calculate minimum and maximum of the column data
-        df_column_min = min(df_column)
-        df_column_max = max(df_column)
-
-        # delta_sat is the width of the saturation band
-        delta_sat = 0.005 * (abs(df_column_max - df_column_min))
-
-        # initiate variables for saturation counters, extended saturation periods and saturation signal
-        max_sat_counter = 0
-        min_sat_counter = 0
-        sat_signal = np.zeros([df_column_length, 1])
-
-        # initiate variables for gap and capsule counters
-        capsule = 0
-        gap = 0
-        capsule_counter = 0
-        gap_counter = 0
-
-        # Loop for saturation detection: Loop goes through every value and checks whether its is in the upper or lower
-        # saturation band and if the derivative is zero. If 3 consecutive values are in the same saturation band,
-        # then saturation is detected.
-        for i in range(len(df_column)):
-
-            if df_column[i] > df_column_max - delta_sat and df_column_derivative[i] == 0:
-                # current value is in the max saturation band
-                # start max_sat_counter
-                max_sat_counter = max_sat_counter + 1
-
-                if max_sat_counter == ext_length:
-                    # saturation detected if 3 consecutive samples were saturated --> extended saturation period
-                    # set max_sat_signal to 1
-                    sat_signal[i - ext_length:i, 0] = 1
-
-                elif max_sat_counter > ext_length:
-                    # set sat_signal to 1
-                    sat_signal[i, 0] = 1
-
-            elif df_column[i] < df_column_min + delta_sat and df_column_derivative[i] == 0:
-                # current value is in the min saturation band
-                # start min_sat_counter
-                min_sat_counter = min_sat_counter + 1
-
-                if min_sat_counter == ext_length:
-                    # saturation detected if 3 consecutive samples were saturated --> extended saturation period
-                    # set sat_signal to 1
-                    sat_signal[i - ext_length:i, 0] = 1
-
-                elif min_sat_counter > ext_length:
-                    # set min_sat_signal to 1
-                    sat_signal[i, 0] = 1
-
-            else:
-                # no saturation, reset counters
-                max_sat_counter = 0
-                min_sat_counter = 0
-
-        sat_signal_copy = sat_signal.copy()
-        for a in range(len(sat_signal_copy)):
-            if sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 1:
-                gap = 30
-                gap_counter = 1
-            elif sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 0:
-                gap = gap + 30
-                gap_counter = gap_counter + 1
-            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 0:
-                gap = gap + 30
-                gap_counter = gap_counter + 1
-                if gap < short_gap:
-                    sat_signal_copy[a - gap_counter:a, 0] = 1
-            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 1:
-                gap = 0
-                gap_counter = 0
-
-        for a in range(len(sat_signal_copy)):
-            if sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 1:
-                capsule_counter = capsule_counter + 1
-                if capsule < short_capsule:
-                    sat_signal_copy[a - capsule_counter:a, 0] = 0
-            elif sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 0:
-                capsule = 0
-                capsule_counter = 0
-            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 0:
-                capsule = 0
-                capsule_counter = 0
-            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 1:
-                capsule = capsule + 30
-                capsule_counter = capsule_counter + 1
-
-        # saturation index in % is calculated
-        saturation_index = float(sum(sat_signal_copy) / df_column_length * 100)
-
-        # the saturation index is compared to the thresholds. the saturation signal is multiplied with a factor if
-        # the index lies above the thresholds. the factors are used for the conditions/colors in treemap
-        # 2 = yellow
-        # 3 = red
-        if lower_threshold < saturation_index < upper_threshold:
-            sat_signal = 2 * sat_signal
-        elif saturation_index >= upper_threshold:
-            sat_signal = 3 * sat_signal
-
-        # sat_signal is converted into a dataframe
-        sat_signal_df = pd.DataFrame(sat_signal)
-        # renaming the dataframe so that every saturation signal has a unique name
-        signal_name = pulled_signals_df.columns[x] + ' Saturation'
-        sat_signal_df.rename(columns={0: signal_name}, inplace=True)
-        # join the saturation dataframes to saturation_signals_df
-        saturation_signals_df = saturation_signals_df.join(sat_signal_df, how='outer')
-
-        data = [{'Signal Name and Path': pulled_signals_df.columns[x], 'Index': round(saturation_index, 1)}]
-        current_saturation_index_df = pd.DataFrame(data)
-        saturation_index_df = pd.concat([saturation_index_df, current_saturation_index_df], ignore_index=True)
-
-    return saturation_signals_df, saturation_index_df
-
-
-pd.options.mode.chained_assignment = None
-
-
-def generate_constraint_index_table(saturation_index_df, new_asset_tree_name):
-    """
-    This functions generates a dictionary with signal name, signal path and constraint index data which is handed over
-    to v.DataTable.
-
-    Parameters
-    ----------
-    saturation_index_df: pd.DataFrame
-        The dataframe that contains the unformatted signal names and constraint index
-    new_asset_tree_name: str
-        User specified name for the new asset tree
-
-    Returns
-    --------
-    saturation_index_dict: dictionary
-        The dictionary that contains the signal names, signal paths and constraint index
-    """
-
-    saturation_index_df = saturation_index_df.sort_values(by=['Index'], ascending=False, ignore_index=True)
-    saturation_index_df = saturation_index_df.head(30)
-
-    for i in range(len(saturation_index_df.index)):
-        # split 'Signal Name and Path' colum and get the length
-        split_index = saturation_index_df['Signal Name and Path'][i].split(" >> ")
-        split_index_length = len(split_index)
-
-        # new column name is the asset name + signal name
-        new_signal_name = split_index[split_index_length - 1]
-        saturation_index_df['Signal'][i] = new_signal_name
-
-        # loop creates the path column
-        for x in range(split_index_length - 1):
-            if x == 0:
-                if new_asset_tree_name == '':
-                    # highest level of the path. The word "Copy" is appended if the user has not specified a name for
-                    # the asset tree copy.
-                    new_path_name_part = split_index[x] + ' Constraint Monitor >> '
-                    saturation_index_df['Path'][i] = new_path_name_part
-                elif new_asset_tree_name != '':
-                    # highest level of the path. The user specified name for the asset tree copy is used.
-                    new_path_name_part = new_asset_tree_name + ' >> '
-                    saturation_index_df['Path'][i] = new_path_name_part
-
-            elif x < split_index_length - 2:
-                # intermediate levels of the path
-                new_path_name_part = split_index[x] + ' >> '
-                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
-
-            elif x == split_index_length - 2:
-                # lowest level of the path
-                new_path_name_part = split_index[x]
-                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
-
-    saturation_index_df_final = saturation_index_df.drop(['Signal Name and Path'], axis=1)
-    saturation_index_dict = saturation_index_df_final.to_dict('records')
-
-    return saturation_index_dict
-
-
-def generate_metadata(joined_signals_df, new_asset_tree_name):
-    """
-    This function generates metadata for the new asset tree and formats the column names in the joined_signals_df.
-
-    Parameters
-    ----------
-    joined_signals_df: pd.DataFrame
-        The dataframe that contains the pulled signals from the original asset tree and the saturation/constraint
-        signals
-    new_asset_tree_name: str
-        User specified name for the new asset tree
-
-    Returns
-    --------
-    metadata: pd.DataFrame
-        The dataframe that contains the 'Build Asset' and 'Build Path' column
-    joined_signals_df: pd.DataFrame
-        The dataframe that contains the pulled signals from the original asset tree and the saturation/constraint
-        signals with formatted names so that the dataframe can be pushed to the workbook
-    """
-    # initiate dataframe with name, asset and path to create metadata for signals
-    metadata = pd.DataFrame(columns=['Build Asset', 'Build Path'], index=range(len(joined_signals_df.columns)))
-
-    # loop iterates through all signal names and gets the name, asset, and path
-    # the signals names in joined_signals_df are changed so that spy.push doesn't get confused
-    for i in range(len(joined_signals_df.columns)):
-        # split current column name and get the length
-        split_index = joined_signals_df.columns[i].split(" >> ")
-        split_index_length = len(split_index)
-
-        # new column name is the asset name + signal name
-        new_column_name = split_index[split_index_length - 2] + ' ' + split_index[split_index_length - 1]
-        joined_signals_df.rename(columns={joined_signals_df.columns[i]: new_column_name}, inplace=True)
-        # metadata asset is the second last value of the split_index
-        metadata['Build Asset'][i] = split_index[split_index_length - 2]
-        # loop creates the path column
-        for x in range(split_index_length - 2):
-            if x == 0:
-                if split_index_length > 3:
-                    if new_asset_tree_name == '':
-                        # highest level of the path. The word "Copy" is appended if the user has not specified a name
-                        # for the asset tree copy.
-                        new_path_name_part = split_index[x] + ' Constraint Monitor >> '
-                        metadata['Build Path'][i] = new_path_name_part
-                    elif new_asset_tree_name != '':
-                        # highest level of the path. The user specified name for the asset tree copy is used.
-                        new_path_name_part = new_asset_tree_name + ' >> '
-                        metadata['Build Path'][i] = new_path_name_part
-
-                elif split_index_length == 3:
-                    if new_asset_tree_name == '':
-                        # highest level of the path. The word "Copy" is appended if the user has not specified a name
-                        # for the asset tree copy.
-                        new_path_name_part = split_index[x] + ' Constraint Monitor'
-                        metadata['Build Path'][i] = new_path_name_part
-                    elif new_asset_tree_name != '':
-                        # highest level of the path. The user specified name for the asset tree copy is used.
-                        new_path_name_part = new_asset_tree_name
-                        metadata['Build Path'][i] = new_path_name_part
-
-            elif x < split_index_length - 3:
-                # intermediate levels of the path
-                new_path_name_part = split_index[x] + ' >> '
-                metadata['Build Path'][i] = metadata['Build Path'][i] + new_path_name_part
-
-            elif x == split_index_length - 3:
-                # lowest level of the path
-                new_path_name_part = split_index[x]
-                metadata['Build Path'][i] = metadata['Build Path'][i] + new_path_name_part
-
-    return metadata, joined_signals_df
-
-
-def recalculate_saturation_index(pulled_signals_df, short_capsule_number, short_capsule_unit, short_gap_number,
-                                 short_gap_unit):
-    """
-    This function is called when the recalculate button is clicked. The function calculates the constrained time
-    percentage from the constraint/saturation signals and generates a dataframe that contains the columns
-    'Signal Name and Path', 'Signal', 'Path' and 'Index'.
-
-    Parameters
-    ----------
-    pulled_signals_df: pd.DataFrame
-        The dataframe that contains the saturation/constraint signals
-    short_capsule_number: int
-        Integer which specifies the length of the capsules that should be closed in the High/Medium Contraint Conditions
-    short_capsule_unit: str
-        Unit (seconds. minutes, hours) of the short capsules
-    short_gap_number: int
-        Integer which specifies the length of the gaps that should be closed in the High/Medium Contraint Conditions
-    short_gap_unit: str
-        Unit (seconds. minutes, hours) of the short gaps
-
-    Returns
-    --------
-    saturation_index_df: pd.DataFrame
-        The dictionary that contains the signal names, signal paths and constrained time percentage
-    """
-    if short_capsule_number == 0:
-        short_capsule = 0
-    elif short_capsule_number > 0:
-        if short_capsule_unit == 'second(s)':
-            short_capsule = short_capsule_number
-        elif short_capsule_unit == 'minute(s)':
-            short_capsule = short_capsule_number * 60
-        elif short_capsule_unit == 'hour(s)':
-            short_capsule = short_capsule_number * 60 * 60
-
-    if short_gap_number == 0:
-        short_gap = 0
-    elif short_gap_number > 0:
-        if short_gap_unit == 'second(s)':
-            short_gap = short_gap_number
-        elif short_gap_unit == 'minute(s)':
-            short_gap = short_gap_number * 60
-        elif short_gap_unit == 'hour(s)':
-            short_gap = short_gap_number * 60 * 60
-
-    saturation_index_df = pd.DataFrame(columns=['Signal Name and Path', 'Signal', 'Path', 'Index'])
-
-    for x in range(len(pulled_signals_df.columns)):
-        sat_signal_copy = np.asarray(pulled_signals_df.iloc[:, x])
-        # get length of the column
-        df_column_length = len(sat_signal_copy)
-
-        if max(sat_signal_copy) == 3:
-            sat_signal_copy = sat_signal_copy / 3
-        if max(sat_signal_copy) == 2:
-            sat_signal_copy = sat_signal_copy / 2
-
-        # initiate variables for gap and capsule counters
-        capsule = 0
-        gap = 0
-        capsule_counter = 0
-        gap_counter = 0
-
-        for a in range(len(sat_signal_copy)):
-            if sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 1:
-                gap = 30
-                gap_counter = 1
-            elif sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 0:
-                gap = gap + 30
-                gap_counter = gap_counter + 1
-            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 0:
-                gap = gap + 30
-                gap_counter = gap_counter + 1
-                if gap < short_gap:
-                    sat_signal_copy[a - gap_counter:a] = 1
-            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 1:
-                gap = 0
-                gap_counter = 0
-
-        for a in range(len(sat_signal_copy)):
-            if sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 1:
-                capsule_counter = capsule_counter + 1
-                if capsule < short_capsule:
-                    sat_signal_copy[a - capsule_counter:a] = 0
-            elif sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 0:
-                capsule = 0
-                capsule_counter = 0
-            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 0:
-                capsule = 0
-                capsule_counter = 0
-            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 1:
-                capsule = capsule + 30
-                capsule_counter = capsule_counter + 1
-
-        # saturation index in % is calculated
-        saturation_index = float(sum(sat_signal_copy) / df_column_length * 100)
-
-        data = [{'Signal Name and Path': pulled_signals_df.columns[x], 'Index': round(saturation_index, 1)}]
-        current_saturation_index_df = pd.DataFrame(data)
-        saturation_index_df = pd.concat([saturation_index_df, current_saturation_index_df], ignore_index=True)
-
-    return saturation_index_df
-
-
-def recalculate_constraint_index_table(saturation_index_df):
-    """
-    This function is called when the recalculate button is clicked. The function generates a dictionary with signal
-    name, signal path and constraint index data which is handed over to v.DataTable.
-
-    Parameters
-    ----------
-    saturation_index_df: pd.DataFrame
-        The dataframe that contains the unformatted signal names and constrained time percentage
-
-    Returns
-    --------
-    saturation_index_dict: dictionary
-        The dictionary that contains the signal names, signal paths and constrained time percentage
-    """
-
-    saturation_index_df = saturation_index_df.sort_values(by=['Index'], ascending=False, ignore_index=True)
-    saturation_index_df = saturation_index_df.head(30)
-
-    for i in range(len(saturation_index_df.index)):
-        # split 'Signal Name and Path' colum and get the length
-        split_index = saturation_index_df['Signal Name and Path'][i].split(" >> ")
-        split_index_length = len(split_index)
-
-        # new column name is the asset name + signal name
-        signal_name = split_index[split_index_length - 1]
-        if 'OP' in signal_name:
-            saturation_index_df['Signal'][i] = 'Controller Output'
-        if 'PV' in signal_name:
-            saturation_index_df['Signal'][i] = 'Process Variable'
-        if 'SP' in signal_name:
-            saturation_index_df['Signal'][i] = 'Setpoint'
-        if 'MV' in signal_name:
-            saturation_index_df['Signal'][i] = 'Manipulated Variable'
-
-        # loop creates the path column
-        for x in range(split_index_length - 1):
-            if x == 0:
-                # highest level of the path.
-                saturation_index_df['Path'][i] = split_index[x] + ' >> '
-
-            elif x < split_index_length - 2:
-                # intermediate levels of the path
-                new_path_name_part = split_index[x] + ' >> '
-                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
-
-            elif x == split_index_length - 2:
-                # lowest level of the path
-                new_path_name_part = split_index[x]
-                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
-
-    saturation_index_df_final = saturation_index_df.drop(['Signal Name and Path'], axis=1)
-    saturation_index_dict = saturation_index_df_final.to_dict('records')
-
-    return saturation_index_dict
+import pandas as pd
+import numpy as np
+
+
+def generate_short_gap_capsule(short_gap_number, short_gap_unit, short_capsule_number, short_capsule_unit):
+    """
+    This function creates string that specify the short gaps and capsules for the High/Medium Constraint Conditions.
+
+    Parameters
+    ----------
+    short_gap_number: int
+        Integer which specifies the length of the gaps that should be closed in the High/Medium Contraint Conditions
+    short_gap_unit: str
+        Unit (seconds. minutes, hours) of the short gaps
+    short_capsule_number: int
+        Integer which specifies the length of the capsules that should be ignored in the High/Medium Contraint
+        Conditions
+    short_capsule_unit: str
+        Unit (seconds. minutes, hours) of the short capsules
+
+    Returns
+    -------
+    short_gap: str
+        String that contains the length and unit of the short gaps e.g. '2min'
+    short_capsule: str
+        String that contains the length and unit of the short capsules e.g. '2min'
+    """
+    if short_gap_unit == 'second(s)':
+        short_gap = str(short_gap_number) + 's'
+    elif short_gap_unit == 'minute(s)':
+        short_gap = str(short_gap_number) + 'min'
+    elif short_gap_unit == 'hour(s)':
+        short_gap = str(short_gap_number) + 'h'
+
+    if short_capsule_number == 0:
+        short_capsule = str(0.1) + 's'
+    if short_capsule_number > 0:
+        if short_capsule_unit == 'second(s)':
+            short_capsule = str(short_capsule_number) + 's'
+        elif short_capsule_unit == 'minute(s)':
+            short_capsule = str(short_capsule_number) + 'min'
+        elif short_capsule_unit == 'hour(s)':
+            short_capsule = str(short_capsule_number) + 'h'
+
+    return short_gap, short_capsule
+
+
+def saturation_detection(pulled_signals_df, checkbox_op, checkbox_pv, checkbox_sp, checkbox_mv, lower_threshold,
+                         upper_threshold, short_gap_number, short_gap_unit, short_capsule_number, short_capsule_unit):
+    """
+    This function analyzes every signal in the pulled_signals_df for saturation/constraints and adds the saturation
+    signal to the saturation_signals_df and the saturation/constraint index to the saturation_index_df.
+
+    Parameters
+    ----------
+    pulled_signals_df: pd.DataFrame
+        The dataframe with all signals in the original asset tree
+    checkbox_op: bool
+        True if OP checkbox is checked. False if OP checkbox is not checked.
+    checkbox_pv: bool
+        True if PV checkbox is checked. False if PV checkbox is not checked.
+    checkbox_sp: bool
+        True if SP checkbox is checked. False if SP checkbox is not checked.
+    checkbox_mv: bool
+        True if MV checkbox is checked. False if MV checkbox is not checked.
+    lower_threshold: float
+        The threshold which is used to set the yellow priority colour in treemap and to create the Medium Constraint
+        Condition.
+    upper_threshold: float
+        The threshold which is used to set the red priority colour in treemap and to create the High Constraint
+        Condition.
+    short_gap_number: int
+        Integer which specifies the length of the gaps that should be closed
+    short_gap_unit: str
+        Unit (seconds. minutes, hours) of the short gaps
+    short_capsule_number:int
+        Integer which specifies the length of the capsule that should be ignored
+    short_capsule_unit: str
+        Unit (seconds. minutes, hours) of the short capsules
+
+    Returns
+    -------
+    saturation_signals_df: pd.DataFrame
+        The dataframe which contains all saturation signals.
+    saturation_index_df: pd.DataFrame
+        The dataframe which contains signal name and contraint index
+    """
+    signals_for_analysis = []
+    if checkbox_op:
+        signals_for_analysis = signals_for_analysis + ['Controller Output']
+    if checkbox_pv:
+        signals_for_analysis = signals_for_analysis + ['Process Variable']
+    if checkbox_sp:
+        signals_for_analysis = signals_for_analysis + ['Setpoint']
+    if checkbox_mv:
+        signals_for_analysis = signals_for_analysis + ['Manipulated Variable']
+
+    if short_capsule_number == 0:
+        short_capsule = 0
+    elif short_capsule_number > 0:
+        if short_capsule_unit == 'second(s)':
+            short_capsule = short_capsule_number
+        elif short_capsule_unit == 'minute(s)':
+            short_capsule = short_capsule_number * 60
+        elif short_capsule_unit == 'hour(s)':
+            short_capsule = short_capsule_number * 60 * 60
+
+    if short_gap_number == 0:
+        short_gap = 0
+    elif short_gap_number > 0:
+        if short_gap_unit == 'second(s)':
+            short_gap = short_gap_number
+        elif short_gap_unit == 'minute(s)':
+            short_gap = short_gap_number * 60
+        elif short_gap_unit == 'hour(s)':
+            short_gap = short_gap_number * 60 * 60
+
+    # initiate empty dataframe for saturation signals saturation/constraint index
+    saturation_signals_df = pd.DataFrame()
+    saturation_index_df = pd.DataFrame(columns=['Signal Name and Path', 'Signal', 'Path', 'Index'])
+
+    # extended period of saturation: at least 3 consecutive samples have to be saturated to detect saturation
+    ext_length = 3
+
+    # Loop goes through all signals in the pull_data dataframe
+    for x in range(len(pulled_signals_df.columns)):
+
+        if 'Mode' in pulled_signals_df.columns[x]:
+            # auto manual mode data should not be analysed by the saturation detection
+            # mode columns are skipped and the loop starts with the next column
+            continue
+
+        if 'Controller Output' in pulled_signals_df.columns[x]:
+            if 'Controller Output' in signals_for_analysis:
+                pass
+            else:
+                continue
+
+        if 'Process Variable' in pulled_signals_df.columns[x]:
+            if 'Process Variable' in signals_for_analysis:
+                pass
+            else:
+                continue
+
+        if 'Setpoint' in pulled_signals_df.columns[x]:
+            if 'Setpoint' in signals_for_analysis:
+                pass
+            else:
+                continue
+
+        if 'Manipulated Variable' in pulled_signals_df.columns[x]:
+            if 'Manipulated Variable' in signals_for_analysis:
+                pass
+            else:
+                continue
+
+        if 'Process Variable' not in pulled_signals_df.columns[x] and 'Controller Output' not in \
+                pulled_signals_df.columns[x] and 'Setpoint' not in pulled_signals_df.columns[
+            x] and 'Manipulated Variable' not in pulled_signals_df.columns[x] and 'Mode' not in \
+                pulled_signals_df.columns[x]:
+            raise RuntimeError(
+                f'''Check if your asset tree has the required layout. Accepted signal names are "Controller Output", 
+                "Process Variable", "Setpoint", "Manipulated Variable" and "Mode". See User Guide for more 
+                information on the required layout''')
+
+            # format the current column as a numpy array
+        df_column = np.asarray(pulled_signals_df.iloc[:, x])
+        # get length of the column
+        df_column_length = len(df_column)
+        # calculate derivative of the column data
+        df_column_derivative = np.gradient(df_column)
+
+        # calculate minimum and maximum of the column data
+        df_column_min = min(df_column)
+        df_column_max = max(df_column)
+
+        # delta_sat is the width of the saturation band
+        delta_sat = 0.005 * (abs(df_column_max - df_column_min))
+
+        # initiate variables for saturation counters, extended saturation periods and saturation signal
+        max_sat_counter = 0
+        min_sat_counter = 0
+        sat_signal = np.zeros([df_column_length, 1])
+
+        # initiate variables for gap and capsule counters
+        capsule = 0
+        gap = 0
+        capsule_counter = 0
+        gap_counter = 0
+
+        # Loop for saturation detection: Loop goes through every value and checks whether its is in the upper or lower
+        # saturation band and if the derivative is zero. If 3 consecutive values are in the same saturation band,
+        # then saturation is detected.
+        for i in range(len(df_column)):
+
+            if df_column[i] > df_column_max - delta_sat and df_column_derivative[i] == 0:
+                # current value is in the max saturation band
+                # start max_sat_counter
+                max_sat_counter = max_sat_counter + 1
+
+                if max_sat_counter == ext_length:
+                    # saturation detected if 3 consecutive samples were saturated --> extended saturation period
+                    # set max_sat_signal to 1
+                    sat_signal[i - ext_length:i, 0] = 1
+
+                elif max_sat_counter > ext_length:
+                    # set sat_signal to 1
+                    sat_signal[i, 0] = 1
+
+            elif df_column[i] < df_column_min + delta_sat and df_column_derivative[i] == 0:
+                # current value is in the min saturation band
+                # start min_sat_counter
+                min_sat_counter = min_sat_counter + 1
+
+                if min_sat_counter == ext_length:
+                    # saturation detected if 3 consecutive samples were saturated --> extended saturation period
+                    # set sat_signal to 1
+                    sat_signal[i - ext_length:i, 0] = 1
+
+                elif min_sat_counter > ext_length:
+                    # set min_sat_signal to 1
+                    sat_signal[i, 0] = 1
+
+            else:
+                # no saturation, reset counters
+                max_sat_counter = 0
+                min_sat_counter = 0
+
+        sat_signal_copy = sat_signal.copy()
+        for a in range(len(sat_signal_copy)):
+            if sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 1:
+                gap = 30
+                gap_counter = 1
+            elif sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 0:
+                gap = gap + 30
+                gap_counter = gap_counter + 1
+            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 0:
+                gap = gap + 30
+                gap_counter = gap_counter + 1
+                if gap < short_gap:
+                    sat_signal_copy[a - gap_counter:a, 0] = 1
+            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 1:
+                gap = 0
+                gap_counter = 0
+
+        for a in range(len(sat_signal_copy)):
+            if sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 1:
+                capsule_counter = capsule_counter + 1
+                if capsule < short_capsule:
+                    sat_signal_copy[a - capsule_counter:a, 0] = 0
+            elif sat_signal_copy[a, 0] == 0 and sat_signal_copy[a - 1, 0] == 0:
+                capsule = 0
+                capsule_counter = 0
+            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 0:
+                capsule = 0
+                capsule_counter = 0
+            elif sat_signal_copy[a, 0] == 1 and sat_signal_copy[a - 1, 0] == 1:
+                capsule = capsule + 30
+                capsule_counter = capsule_counter + 1
+
+        # saturation index in % is calculated
+        saturation_index = float(sum(sat_signal_copy) / df_column_length * 100)
+
+        # the saturation index is compared to the thresholds. the saturation signal is multiplied with a factor if
+        # the index lies above the thresholds. the factors are used for the conditions/colors in treemap
+        # 2 = yellow
+        # 3 = red
+        if lower_threshold < saturation_index < upper_threshold:
+            sat_signal = 2 * sat_signal
+        elif saturation_index >= upper_threshold:
+            sat_signal = 3 * sat_signal
+
+        # sat_signal is converted into a dataframe
+        sat_signal_df = pd.DataFrame(sat_signal)
+        # renaming the dataframe so that every saturation signal has a unique name
+        signal_name = pulled_signals_df.columns[x] + ' Saturation'
+        sat_signal_df.rename(columns={0: signal_name}, inplace=True)
+        # join the saturation dataframes to saturation_signals_df
+        saturation_signals_df = saturation_signals_df.join(sat_signal_df, how='outer')
+
+        data = [{'Signal Name and Path': pulled_signals_df.columns[x], 'Index': round(saturation_index, 1)}]
+        current_saturation_index_df = pd.DataFrame(data)
+        saturation_index_df = pd.concat([saturation_index_df, current_saturation_index_df], ignore_index=True)
+
+    return saturation_signals_df, saturation_index_df
+
+
+pd.options.mode.chained_assignment = None
+
+
+def generate_constraint_index_table(saturation_index_df, new_asset_tree_name):
+    """
+    This functions generates a dictionary with signal name, signal path and constraint index data which is handed over
+    to v.DataTable.
+
+    Parameters
+    ----------
+    saturation_index_df: pd.DataFrame
+        The dataframe that contains the unformatted signal names and constraint index
+    new_asset_tree_name: str
+        User specified name for the new asset tree
+
+    Returns
+    --------
+    saturation_index_dict: dictionary
+        The dictionary that contains the signal names, signal paths and constraint index
+    """
+
+    saturation_index_df = saturation_index_df.sort_values(by=['Index'], ascending=False, ignore_index=True)
+    saturation_index_df = saturation_index_df.head(30)
+
+    for i in range(len(saturation_index_df.index)):
+        # split 'Signal Name and Path' colum and get the length
+        split_index = saturation_index_df['Signal Name and Path'][i].split(" >> ")
+        split_index_length = len(split_index)
+
+        # new column name is the asset name + signal name
+        new_signal_name = split_index[split_index_length - 1]
+        saturation_index_df['Signal'][i] = new_signal_name
+
+        # loop creates the path column
+        for x in range(split_index_length - 1):
+            if x == 0:
+                if new_asset_tree_name == '':
+                    # highest level of the path. The word "Copy" is appended if the user has not specified a name for
+                    # the asset tree copy.
+                    new_path_name_part = split_index[x] + ' Constraint Monitor >> '
+                    saturation_index_df['Path'][i] = new_path_name_part
+                elif new_asset_tree_name != '':
+                    # highest level of the path. The user specified name for the asset tree copy is used.
+                    new_path_name_part = new_asset_tree_name + ' >> '
+                    saturation_index_df['Path'][i] = new_path_name_part
+
+            elif x < split_index_length - 2:
+                # intermediate levels of the path
+                new_path_name_part = split_index[x] + ' >> '
+                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
+
+            elif x == split_index_length - 2:
+                # lowest level of the path
+                new_path_name_part = split_index[x]
+                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
+
+    saturation_index_df_final = saturation_index_df.drop(['Signal Name and Path'], axis=1)
+    saturation_index_dict = saturation_index_df_final.to_dict('records')
+
+    return saturation_index_dict
+
+
+def generate_metadata(joined_signals_df, new_asset_tree_name):
+    """
+    This function generates metadata for the new asset tree and formats the column names in the joined_signals_df.
+
+    Parameters
+    ----------
+    joined_signals_df: pd.DataFrame
+        The dataframe that contains the pulled signals from the original asset tree and the saturation/constraint
+        signals
+    new_asset_tree_name: str
+        User specified name for the new asset tree
+
+    Returns
+    --------
+    metadata: pd.DataFrame
+        The dataframe that contains the 'Build Asset' and 'Build Path' column
+    joined_signals_df: pd.DataFrame
+        The dataframe that contains the pulled signals from the original asset tree and the saturation/constraint
+        signals with formatted names so that the dataframe can be pushed to the workbook
+    """
+    # initiate dataframe with name, asset and path to create metadata for signals
+    metadata = pd.DataFrame(columns=['Build Asset', 'Build Path'], index=range(len(joined_signals_df.columns)))
+
+    # loop iterates through all signal names and gets the name, asset, and path
+    # the signals names in joined_signals_df are changed so that spy.push doesn't get confused
+    for i in range(len(joined_signals_df.columns)):
+        # split current column name and get the length
+        split_index = joined_signals_df.columns[i].split(" >> ")
+        split_index_length = len(split_index)
+
+        # new column name is the asset name + signal name
+        new_column_name = split_index[split_index_length - 2] + ' ' + split_index[split_index_length - 1]
+        joined_signals_df.rename(columns={joined_signals_df.columns[i]: new_column_name}, inplace=True)
+        # metadata asset is the second last value of the split_index
+        metadata['Build Asset'][i] = split_index[split_index_length - 2]
+        # loop creates the path column
+        for x in range(split_index_length - 2):
+            if x == 0:
+                if split_index_length > 3:
+                    if new_asset_tree_name == '':
+                        # highest level of the path. The word "Copy" is appended if the user has not specified a name
+                        # for the asset tree copy.
+                        new_path_name_part = split_index[x] + ' Constraint Monitor >> '
+                        metadata['Build Path'][i] = new_path_name_part
+                    elif new_asset_tree_name != '':
+                        # highest level of the path. The user specified name for the asset tree copy is used.
+                        new_path_name_part = new_asset_tree_name + ' >> '
+                        metadata['Build Path'][i] = new_path_name_part
+
+                elif split_index_length == 3:
+                    if new_asset_tree_name == '':
+                        # highest level of the path. The word "Copy" is appended if the user has not specified a name
+                        # for the asset tree copy.
+                        new_path_name_part = split_index[x] + ' Constraint Monitor'
+                        metadata['Build Path'][i] = new_path_name_part
+                    elif new_asset_tree_name != '':
+                        # highest level of the path. The user specified name for the asset tree copy is used.
+                        new_path_name_part = new_asset_tree_name
+                        metadata['Build Path'][i] = new_path_name_part
+
+            elif x < split_index_length - 3:
+                # intermediate levels of the path
+                new_path_name_part = split_index[x] + ' >> '
+                metadata['Build Path'][i] = metadata['Build Path'][i] + new_path_name_part
+
+            elif x == split_index_length - 3:
+                # lowest level of the path
+                new_path_name_part = split_index[x]
+                metadata['Build Path'][i] = metadata['Build Path'][i] + new_path_name_part
+
+    return metadata, joined_signals_df
+
+
+def recalculate_saturation_index(pulled_signals_df, short_capsule_number, short_capsule_unit, short_gap_number,
+                                 short_gap_unit):
+    """
+    This function is called when the recalculate button is clicked. The function calculates the constrained time
+    percentage from the constraint/saturation signals and generates a dataframe that contains the columns
+    'Signal Name and Path', 'Signal', 'Path' and 'Index'.
+
+    Parameters
+    ----------
+    pulled_signals_df: pd.DataFrame
+        The dataframe that contains the saturation/constraint signals
+    short_capsule_number: int
+        Integer which specifies the length of the capsules that should be closed in the High/Medium Contraint Conditions
+    short_capsule_unit: str
+        Unit (seconds. minutes, hours) of the short capsules
+    short_gap_number: int
+        Integer which specifies the length of the gaps that should be closed in the High/Medium Contraint Conditions
+    short_gap_unit: str
+        Unit (seconds. minutes, hours) of the short gaps
+
+    Returns
+    --------
+    saturation_index_df: pd.DataFrame
+        The dictionary that contains the signal names, signal paths and constrained time percentage
+    """
+    if short_capsule_number == 0:
+        short_capsule = 0
+    elif short_capsule_number > 0:
+        if short_capsule_unit == 'second(s)':
+            short_capsule = short_capsule_number
+        elif short_capsule_unit == 'minute(s)':
+            short_capsule = short_capsule_number * 60
+        elif short_capsule_unit == 'hour(s)':
+            short_capsule = short_capsule_number * 60 * 60
+
+    if short_gap_number == 0:
+        short_gap = 0
+    elif short_gap_number > 0:
+        if short_gap_unit == 'second(s)':
+            short_gap = short_gap_number
+        elif short_gap_unit == 'minute(s)':
+            short_gap = short_gap_number * 60
+        elif short_gap_unit == 'hour(s)':
+            short_gap = short_gap_number * 60 * 60
+
+    saturation_index_df = pd.DataFrame(columns=['Signal Name and Path', 'Signal', 'Path', 'Index'])
+
+    for x in range(len(pulled_signals_df.columns)):
+        sat_signal_copy = np.asarray(pulled_signals_df.iloc[:, x])
+        # get length of the column
+        df_column_length = len(sat_signal_copy)
+
+        if max(sat_signal_copy) == 3:
+            sat_signal_copy = sat_signal_copy / 3
+        if max(sat_signal_copy) == 2:
+            sat_signal_copy = sat_signal_copy / 2
+
+        # initiate variables for gap and capsule counters
+        capsule = 0
+        gap = 0
+        capsule_counter = 0
+        gap_counter = 0
+
+        for a in range(len(sat_signal_copy)):
+            if sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 1:
+                gap = 30
+                gap_counter = 1
+            elif sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 0:
+                gap = gap + 30
+                gap_counter = gap_counter + 1
+            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 0:
+                gap = gap + 30
+                gap_counter = gap_counter + 1
+                if gap < short_gap:
+                    sat_signal_copy[a - gap_counter:a] = 1
+            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 1:
+                gap = 0
+                gap_counter = 0
+
+        for a in range(len(sat_signal_copy)):
+            if sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 1:
+                capsule_counter = capsule_counter + 1
+                if capsule < short_capsule:
+                    sat_signal_copy[a - capsule_counter:a] = 0
+            elif sat_signal_copy[a] == 0 and sat_signal_copy[a - 1] == 0:
+                capsule = 0
+                capsule_counter = 0
+            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 0:
+                capsule = 0
+                capsule_counter = 0
+            elif sat_signal_copy[a] == 1 and sat_signal_copy[a - 1] == 1:
+                capsule = capsule + 30
+                capsule_counter = capsule_counter + 1
+
+        # saturation index in % is calculated
+        saturation_index = float(sum(sat_signal_copy) / df_column_length * 100)
+
+        data = [{'Signal Name and Path': pulled_signals_df.columns[x], 'Index': round(saturation_index, 1)}]
+        current_saturation_index_df = pd.DataFrame(data)
+        saturation_index_df = pd.concat([saturation_index_df, current_saturation_index_df], ignore_index=True)
+
+    return saturation_index_df
+
+
+def recalculate_constraint_index_table(saturation_index_df):
+    """
+    This function is called when the recalculate button is clicked. The function generates a dictionary with signal
+    name, signal path and constraint index data which is handed over to v.DataTable.
+
+    Parameters
+    ----------
+    saturation_index_df: pd.DataFrame
+        The dataframe that contains the unformatted signal names and constrained time percentage
+
+    Returns
+    --------
+    saturation_index_dict: dictionary
+        The dictionary that contains the signal names, signal paths and constrained time percentage
+    """
+
+    saturation_index_df = saturation_index_df.sort_values(by=['Index'], ascending=False, ignore_index=True)
+    saturation_index_df = saturation_index_df.head(30)
+
+    for i in range(len(saturation_index_df.index)):
+        # split 'Signal Name and Path' colum and get the length
+        split_index = saturation_index_df['Signal Name and Path'][i].split(" >> ")
+        split_index_length = len(split_index)
+
+        # new column name is the asset name + signal name
+        signal_name = split_index[split_index_length - 1]
+        if 'OP' in signal_name:
+            saturation_index_df['Signal'][i] = 'Controller Output'
+        if 'PV' in signal_name:
+            saturation_index_df['Signal'][i] = 'Process Variable'
+        if 'SP' in signal_name:
+            saturation_index_df['Signal'][i] = 'Setpoint'
+        if 'MV' in signal_name:
+            saturation_index_df['Signal'][i] = 'Manipulated Variable'
+
+        # loop creates the path column
+        for x in range(split_index_length - 1):
+            if x == 0:
+                # highest level of the path.
+                saturation_index_df['Path'][i] = split_index[x] + ' >> '
+
+            elif x < split_index_length - 2:
+                # intermediate levels of the path
+                new_path_name_part = split_index[x] + ' >> '
+                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
+
+            elif x == split_index_length - 2:
+                # lowest level of the path
+                new_path_name_part = split_index[x]
+                saturation_index_df['Path'][i] = saturation_index_df['Path'][i] + new_path_name_part
+
+    saturation_index_df_final = saturation_index_df.drop(['Signal Name and Path'], axis=1)
+    saturation_index_dict = saturation_index_df_final.to_dict('records')
+
+    return saturation_index_dict
```

## seeq/addons/constraintdetection/_version.py

```diff
@@ -1 +1 @@
-__version__ = '0.0.4'
+__version__ = '0.0.41'
```

## seeq/addons/constraintdetection/utils/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-from ._common import validate_argument_types, print_red
-from ._permissions import add_datalab_project_ace, get_user, get_user_group
-from ._sdl import sanitize_sdl_url, get_datalab_project_id, check_spy_version, addon_tool_management, \
-    get_workbook_worksheet_workstep_ids
-
-_user_guide = 'https://seeq12.github.io/seeq-mps/user_guide.html'
-
-__all__ = ['validate_argument_types', 'print_red', 'add_datalab_project_ace', 'get_user',
-           'get_user_group', 'sanitize_sdl_url', 'get_datalab_project_id', 'addon_tool_management',
+from ._common import validate_argument_types, print_red
+from ._permissions import add_datalab_project_ace, get_user, get_user_group
+from ._sdl import sanitize_sdl_url, get_datalab_project_id, check_spy_version, addon_tool_management, \
+    get_workbook_worksheet_workstep_ids
+
+_user_guide = 'https://seeq12.github.io/seeq-mps/user_guide.html'
+
+__all__ = ['validate_argument_types', 'print_red', 'add_datalab_project_ace', 'get_user',
+           'get_user_group', 'sanitize_sdl_url', 'get_datalab_project_id', 'addon_tool_management',
            'get_workbook_worksheet_workstep_ids', 'check_spy_version']
```

## seeq/addons/constraintdetection/utils/_common.py

 * *Ordering differences only*

```diff
@@ -1,18 +1,18 @@
-def validate_argument_types(expected_types):
-    for _value, _name, _types in expected_types:
-        if _value is None:
-            continue
-
-        if not isinstance(_value, _types):
-            if isinstance(_types, tuple):
-                acceptable_types = ' or '.join([_t.__name__ for _t in _types])
-            else:
-                acceptable_types = _types.__name__
-
-            raise TypeError("Argument '%s' should be type %s, but is type %s" % (_name, acceptable_types,
-                                                                                 type(_value).__name__))
-
-    return {_name: _value for _value, _name, _types in expected_types}
-
-
+def validate_argument_types(expected_types):
+    for _value, _name, _types in expected_types:
+        if _value is None:
+            continue
+
+        if not isinstance(_value, _types):
+            if isinstance(_types, tuple):
+                acceptable_types = ' or '.join([_t.__name__ for _t in _types])
+            else:
+                acceptable_types = _types.__name__
+
+            raise TypeError("Argument '%s' should be type %s, but is type %s" % (_name, acceptable_types,
+                                                                                 type(_value).__name__))
+
+    return {_name: _value for _value, _name, _types in expected_types}
+
+
 def print_red(text): print(f"\x1b[31m{text}\x1b[0m")
```

## seeq/addons/constraintdetection/utils/_permissions.py

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-from seeq.sdk.rest import ApiException
-from ._common import print_red
-
-def add_datalab_project_ace(data_lab_project_id, ace_input, items_api):
-    if data_lab_project_id:
-        try:
-            items_api.add_access_control_entry(id=data_lab_project_id, body=ace_input)
-        except Exception as error:
-            print_red(error.body)
-
-def get_user_group(group_name, user_groups_api):
-    try:
-        group = user_groups_api.get_user_groups(name_search=group_name)
-        assert len(group.items) != 0, 'No group named "%s" was found' % group_name
-        assert len(group.items) == 1, 'More that one group named "%s" was found' % group_name
-        return group
-    except AssertionError as error:
-        print_red(error)
-    except ApiException as error:
-        print_red(error.body)
-
-
-def get_user(user_name, users_api):
-    try:
-        user_ = users_api.get_users(username_search=user_name)
-        if len(user_.users) == 0:
-            raise ValueError(f'No user named {user_name} was found')
-        if len(user_.users) > 1:
-            raise ValueError(f'More than one user named {user_name} was found')
-        return user_
-    except AssertionError as error:
-        print_red(error)
-    except ApiException as error:
+from seeq.sdk.rest import ApiException
+from ._common import print_red
+
+def add_datalab_project_ace(data_lab_project_id, ace_input, items_api):
+    if data_lab_project_id:
+        try:
+            items_api.add_access_control_entry(id=data_lab_project_id, body=ace_input)
+        except Exception as error:
+            print_red(error.body)
+
+def get_user_group(group_name, user_groups_api):
+    try:
+        group = user_groups_api.get_user_groups(name_search=group_name)
+        assert len(group.items) != 0, 'No group named "%s" was found' % group_name
+        assert len(group.items) == 1, 'More that one group named "%s" was found' % group_name
+        return group
+    except AssertionError as error:
+        print_red(error)
+    except ApiException as error:
+        print_red(error.body)
+
+
+def get_user(user_name, users_api):
+    try:
+        user_ = users_api.get_users(username_search=user_name)
+        if len(user_.users) == 0:
+            raise ValueError(f'No user named {user_name} was found')
+        if len(user_.users) > 1:
+            raise ValueError(f'More than one user named {user_name} was found')
+        return user_
+    except AssertionError as error:
+        print_red(error)
+    except ApiException as error:
         print_red(error.body)
```

## Comparing `seeq_constraintdetection-0.0.4.dist-info/LICENSE` & `seeq_constraintdetection-0.0.41.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
+Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
    limitations under the License.
```

## Comparing `seeq_constraintdetection-0.0.4.dist-info/METADATA` & `seeq_constraintdetection-0.0.41.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: seeq-constraintdetection
-Version: 0.0.4
+Version: 0.0.41
 Summary: Constraint and saturation detection in control loop data in Seeq
 Home-page: https://github.com/HAW-Process-Automation/Constraint-Detection
 Author: Lea Tiedemann
 Author-email: lea.tiedemann@seeq.com
 License: Apache License 2.0
 Platform: Linux
 Platform: Windows
@@ -15,24 +15,30 @@
 License-File: LICENSE
 License-File: NOTICE
 Requires-Dist: ipyvuetify (>=1.8.2)
 Requires-Dist: numpy (>=1.20.1)
 Requires-Dist: pandas (>=1.2.4)
 Requires-Dist: pytz (~=2021.1)
 
+[![N|Solid](https://github.com/LeaTiedemann/Constraint-Detection/blob/main/HAW_Seeq.png)](https://www.seeq.com)
+
+[![N|Scheme](https://github.com/LeaTiedemann/Constraint-Detection/blob/main/treemap_use_case_1.PNG)](https://constraint-detection.readthedocs.io/en/latest/index.html)
+
 **seeq-constraintdetection** is an Add-on for control loop performance monitoring. It is used to find time periods when a control signal is constrained or saturated. This means that the signal is at its minimum or maximum and only 
 deviates from there for short time periods. Control signals include all signals which are related to a control loop: Controller output (OP), setpoint (SP), process variable (PV), manipulated variable (MV) and auto-manual mode. 
 Saturation occurs in the OP whereas constraints occur in the PV and MV due to their physical limitations (e.g. measuring range, actuator range) or in the SP (e.g. when model predictive control is applied). The Constraint Detection 
 Add-on analyses the OP, SP, PV and MV and and generates a worksheet in treemap view where every controller panel is coloured according to the time-percentage a signal is constrained/saturated in the analysis time period.
 
 # Documentation
 [Documentation for **seeq-constraintdetection**](https://constraint-detection.readthedocs.io/en/latest/index.html)
 
 # User Guide
-[**seeq-constraintdetection** User Guide](https://constraint-detection.readthedocs.io/en/latest/userguide.html) provides an explanation of the required asset tree structure and the workflow in the user interface.
+[**seeq-constraintdetection** User Guide](https://constraint-detection.readthedocs.io/en/latest/userguide.html) provides an explanation of the required asset tree structure and the workflow in the user interface. The video below gives an introduction about the Constraint Detection Add-on.
+
+https://user-images.githubusercontent.com/111488243/192772896-1b0b19a9-c70c-4486-994b-a8a13f5eb830.mp4
 
 # Installation
 The backend of **seeq-constraintdetection** requires **Python 3.7** or later.
 
 ## Dependencies
 See [`requirements.txt`](https://github.com/HAW-Process-Automation/Constraint-Detection/blob/main/requirements.txt) file for a list of dependencies and versions. Additionally, you will need to install the `seeq` module with the appropriate version that matches your Seeq server. For more information on the `seeq` module see [seeq at pypi](https://pypi.org/project/seeq/).
 
@@ -41,15 +47,15 @@
 
 * Seeq Data Lab (>=R54.1.6 or >=R56.1.4)
 * `seeq` module whose version matches the Seeq server version
 * Seeq administrator access
 * Enable Add-on in the Seeq server
 
 ## User Installation (Seeq Data Lab)
-The latest build of the project can be found [here](https://pypi.org) as a wheel file. The file is published as a courtesy and does not imply any guarantee or obligation for support from the publisher.
+The latest build of the project can be found [here](https://pypi.org/project/seeq-constraintdetection/) as a wheel file. The file is published as a courtesy and does not imply any guarantee or obligation for support from the publisher.
 
 1. Create a **new** Seeq Data Lab project and open the **Terminal** window
 2. Run `pip install seeq-constraintdetection`
 3. Run `python -m seeq.addons.constraintdetection`
 4. Follow the instructions when prompted. ("Username or Access Key" is what you use to log in to Seeq. "Password" is your password for logging into Seeq.)
 
 There are additional **Options** for the Add-on installation. These include `--users` and `--groups`. These can be used to change permissions for the Add-on Tool.
@@ -63,15 +69,15 @@
 
 * Official source code repo: [https://github.com/HAW-Process-Automation/Constraint-Detection](https://github.com/HAW-Process-Automation/Constraint-Detection)
 * Issue tracker: [https://github.com/HAW-Process-Automation/Constraint-Detection/issues](https://github.com/HAW-Process-Automation/Constraint-Detection/issues)
 
 ## Source code
 You can get started by cloning the repository with the command: 
 ```
-git clone git@github.com:HAW-Process-Automation/seeq-constraintdetection.git
+git clone git@github.com:HAW-Process-Automation/Constraint-Detection.git
 ```
 
 ## Installation from source
 For development work, it is highly recommended creating a python virtual environment and install the package in that working environment. If you are not familiar with python virtual environments, you can take a look [here](https://docs.python.org/3.8/tutorial/venv.html).
 
 Once your virtual environment is activated, you can install requirements and **seeq-constraintdetection** from source with:
 ```
@@ -86,11 +92,11 @@
 
 Maintainer: Lea Tiedemann
 
 # Citation
 
 Please cite this work as:
 ```
-seeq-constraintdetection v0.0.4
-Seeq Corporation, 2022
+seeq-constraintdetection v0.0.41
+HAW Process Automation
 https://github.com/HAW-Process-Automation/Constraint-Detection
 ```
```

## Comparing `seeq_constraintdetection-0.0.4.dist-info/NOTICE` & `seeq_constraintdetection-0.0.41.dist-info/NOTICE`

 * *Files 23% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-00000000: 0d0a 436f 7079 7269 6768 7420 5b32 3032  ..Copyright [202
-00000010: 325d 205b 5365 6571 2043 6f72 706f 7261  2] [Seeq Corpora
-00000020: 7469 6f6e 5d0d 0a0d 0a4c 6963 656e 7365  tion]....License
-00000030: 6420 756e 6465 7220 7468 6520 4170 6163  d under the Apac
-00000040: 6865 204c 6963 656e 7365 2c20 5665 7273  he License, Vers
-00000050: 696f 6e20 322e 3020 2874 6865 2022 4c69  ion 2.0 (the "Li
-00000060: 6365 6e73 6522 293b 2079 6f75 206d 6179  cense"); you may
-00000070: 206e 6f74 2075 7365 2074 6869 7320 6669   not use this fi
-00000080: 6c65 2065 7863 6570 7420 696e 2063 6f6d  le except in com
-00000090: 706c 6961 6e63 6520 7769 7468 2074 6865  pliance with the
-000000a0: 0d0a 4c69 6365 6e73 652e 2059 6f75 206d  ..License. You m
-000000b0: 6179 206f 6274 6169 6e20 6120 636f 7079  ay obtain a copy
-000000c0: 206f 6620 7468 6520 4c69 6365 6e73 6520   of the License 
-000000d0: 6174 0d0a 0d0a 2020 2020 2020 2068 7474  at....       htt
-000000e0: 703a 2f2f 7777 772e 6170 6163 6865 2e6f  p://www.apache.o
-000000f0: 7267 2f6c 6963 656e 7365 732f 4c49 4345  rg/licenses/LICE
-00000100: 4e53 452d 322e 300d 0a0d 0a55 6e6c 6573  NSE-2.0....Unles
-00000110: 7320 7265 7175 6972 6564 2062 7920 6170  s required by ap
-00000120: 706c 6963 6162 6c65 206c 6177 206f 7220  plicable law or 
-00000130: 6167 7265 6564 2074 6f20 696e 2077 7269  agreed to in wri
-00000140: 7469 6e67 2c20 736f 6674 7761 7265 2064  ting, software d
-00000150: 6973 7472 6962 7574 6564 2075 6e64 6572  istributed under
-00000160: 2074 6865 204c 6963 656e 7365 2069 7320   the License is 
-00000170: 6469 7374 7269 6275 7465 6420 6f6e 2061  distributed on a
-00000180: 6e20 0d0a 2241 5320 4953 2220 4241 5349  n .."AS IS" BASI
-00000190: 532c 2057 4954 484f 5554 2057 4152 5241  S, WITHOUT WARRA
-000001a0: 4e54 4945 5320 4f52 2043 4f4e 4449 5449  NTIES OR CONDITI
-000001b0: 4f4e 5320 4f46 2041 4e59 204b 494e 442c  ONS OF ANY KIND,
-000001c0: 2065 6974 6865 7220 6578 7072 6573 7320   either express 
-000001d0: 6f72 2069 6d70 6c69 6564 2e20 5365 6520  or implied. See 
-000001e0: 7468 6520 4c69 6365 6e73 6520 666f 7220  the License for 
-000001f0: 7468 6520 7370 6563 6966 6963 0d0a 6c61  the specific..la
-00000200: 6e67 7561 6765 2067 6f76 6572 6e69 6e67  nguage governing
-00000210: 2070 6572 6d69 7373 696f 6e73 2061 6e64   permissions and
-00000220: 206c 696d 6974 6174 696f 6e73 2075 6e64   limitations und
-00000230: 6572 2074 6865 204c 6963 656e 7365 2e0a  er the License..
+00000000: 0a43 6f70 7972 6967 6874 205b 3230 3232  .Copyright [2022
+00000010: 5d20 5b53 6565 7120 436f 7270 6f72 6174  ] [Seeq Corporat
+00000020: 696f 6e5d 0a0a 4c69 6365 6e73 6564 2075  ion]..Licensed u
+00000030: 6e64 6572 2074 6865 2041 7061 6368 6520  nder the Apache 
+00000040: 4c69 6365 6e73 652c 2056 6572 7369 6f6e  License, Version
+00000050: 2032 2e30 2028 7468 6520 224c 6963 656e   2.0 (the "Licen
+00000060: 7365 2229 3b20 796f 7520 6d61 7920 6e6f  se"); you may no
+00000070: 7420 7573 6520 7468 6973 2066 696c 6520  t use this file 
+00000080: 6578 6365 7074 2069 6e20 636f 6d70 6c69  except in compli
+00000090: 616e 6365 2077 6974 6820 7468 650a 4c69  ance with the.Li
+000000a0: 6365 6e73 652e 2059 6f75 206d 6179 206f  cense. You may o
+000000b0: 6274 6169 6e20 6120 636f 7079 206f 6620  btain a copy of 
+000000c0: 7468 6520 4c69 6365 6e73 6520 6174 0a0a  the License at..
+000000d0: 2020 2020 2020 2068 7474 703a 2f2f 7777         http://ww
+000000e0: 772e 6170 6163 6865 2e6f 7267 2f6c 6963  w.apache.org/lic
+000000f0: 656e 7365 732f 4c49 4345 4e53 452d 322e  enses/LICENSE-2.
+00000100: 300a 0a55 6e6c 6573 7320 7265 7175 6972  0..Unless requir
+00000110: 6564 2062 7920 6170 706c 6963 6162 6c65  ed by applicable
+00000120: 206c 6177 206f 7220 6167 7265 6564 2074   law or agreed t
+00000130: 6f20 696e 2077 7269 7469 6e67 2c20 736f  o in writing, so
+00000140: 6674 7761 7265 2064 6973 7472 6962 7574  ftware distribut
+00000150: 6564 2075 6e64 6572 2074 6865 204c 6963  ed under the Lic
+00000160: 656e 7365 2069 7320 6469 7374 7269 6275  ense is distribu
+00000170: 7465 6420 6f6e 2061 6e20 0a22 4153 2049  ted on an ."AS I
+00000180: 5322 2042 4153 4953 2c20 5749 5448 4f55  S" BASIS, WITHOU
+00000190: 5420 5741 5252 414e 5449 4553 204f 5220  T WARRANTIES OR 
+000001a0: 434f 4e44 4954 494f 4e53 204f 4620 414e  CONDITIONS OF AN
+000001b0: 5920 4b49 4e44 2c20 6569 7468 6572 2065  Y KIND, either e
+000001c0: 7870 7265 7373 206f 7220 696d 706c 6965  xpress or implie
+000001d0: 642e 2053 6565 2074 6865 204c 6963 656e  d. See the Licen
+000001e0: 7365 2066 6f72 2074 6865 2073 7065 6369  se for the speci
+000001f0: 6669 630a 6c61 6e67 7561 6765 2067 6f76  fic.language gov
+00000200: 6572 6e69 6e67 2070 6572 6d69 7373 696f  erning permissio
+00000210: 6e73 2061 6e64 206c 696d 6974 6174 696f  ns and limitatio
+00000220: 6e73 2075 6e64 6572 2074 6865 204c 6963  ns under the Lic
+00000230: 656e 7365 2e0a                           ense..
```

## Comparing `seeq_constraintdetection-0.0.4.dist-info/RECORD` & `seeq_constraintdetection-0.0.41.dist-info/RECORD`

 * *Files 13% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 seeq/addons/constraintdetection/_SPy_functions.py,sha256=fd5eaARtlaXIxenuQEM4FoKjfKYdywMKO683riQyhoo,21837
-seeq/addons/constraintdetection/__init__.py,sha256=qOqtj9cfZNfXREjaUOj9WEG3QCDmzGRnJIDFc-azAwY,857
-seeq/addons/constraintdetection/__main__.py,sha256=EnrYahZjA6oSbceSxUSFxPVq2y0kpsihh8KRNGmJ_q0,6494
-seeq/addons/constraintdetection/_copy.py,sha256=O4lB0fgtdwwcImdBXvDocEBkctR9GQGcznvGnGcV4xo,3022
-seeq/addons/constraintdetection/_saturation_detection.py,sha256=J9z6iQjqQ1oeSFjyLhMV8-1TM_lheX3AYyATxshUmPk,26666
+seeq/addons/constraintdetection/__init__.py,sha256=VE-t5XGrzZD376i6Alj-nJRdEo8Zoz8vUrHF8P_WPEQ,845
+seeq/addons/constraintdetection/__main__.py,sha256=bvlTlpd2UHGK8VEOjK_l9Et80pRSTfNpwoe9NwU1nPE,6513
+seeq/addons/constraintdetection/_copy.py,sha256=VpXhGQdbkpZsLLNvBuJUjnEKYcMVREHUrRJNogQXd2Q,2953
+seeq/addons/constraintdetection/_saturation_detection.py,sha256=-2VSxaB_KfWrzp_aO2hi-jExi58CIaZa6AMt-jXJC0o,26085
 seeq/addons/constraintdetection/_seeq_add_on.py,sha256=dZ0EF4Tg1SZZOOZGzCuh6LC3XoB3vhE3dbRpQA9Pz5A,38551
-seeq/addons/constraintdetection/_version.py,sha256=Qkdiz6Ybn1PE1SlWhKAQBmETf7pQ0yr5HmkqLVDxsqE,21
+seeq/addons/constraintdetection/_version.py,sha256=KAM9ToHxLtTawfvo5OEM8A2apxkqANHWZfbsR65t630,22
 seeq/addons/constraintdetection/deployment_notebook/constraint_detection_master.ipynb,sha256=cZBR7regGpyOn7RRhKgly7PTcj7jKcHQRXXGkjmITjE,895
 seeq/addons/constraintdetection/deployment_notebook/thresholds.PNG,sha256=AkADn6FyIYn9_jctUINGKYPfI6BOKdN8AlGt-fwMnG4,24572
-seeq/addons/constraintdetection/utils/__init__.py,sha256=SseRHlLxCPnpVEwJ13PeurDYKcT3B8kU8yilIqkn7l0,613
-seeq/addons/constraintdetection/utils/_common.py,sha256=A-_nNc4Ogp4F6Qe7WQ9TenJLeoK9pROGzYSy_YwRgq0,731
-seeq/addons/constraintdetection/utils/_permissions.py,sha256=zkDeb2xFzh1tqc-MajeA1fHZbmLaFTOb1d0K5rpNnss,1298
+seeq/addons/constraintdetection/utils/__init__.py,sha256=ux6Jshuxt7VQsv6jFENJSA9RhuLXLKjGAqhMVX5_ehY,604
+seeq/addons/constraintdetection/utils/_common.py,sha256=iIv5LY4ydSfR7oelxy73ADHPD1CKKtE9_xUGWtHbQNQ,714
+seeq/addons/constraintdetection/utils/_permissions.py,sha256=oLEaAMVxYXKBdz29NJI_Dx3TlrppDL2uOyzuvC4mcAk,1265
 seeq/addons/constraintdetection/utils/_sdl.py,sha256=bCeOeW0e8jqvfJ1a07BCTUS7UTuFFHWNbSDZxZfBlY0,7863
-seeq_constraintdetection-0.0.4.dist-info/LICENSE,sha256=F96EzotgWhhpnQTW2TcdoqrMDir1jyEo6H915tGQ-QE,11524
-seeq_constraintdetection-0.0.4.dist-info/METADATA,sha256=458uzP_x0DovbsvmS8ViChXSFxBrH5Zl3wvop5BZXgc,5086
-seeq_constraintdetection-0.0.4.dist-info/NOTICE,sha256=j4fLOMorBtglULfp34W9J1r_gLh6UYpldNGpMJiL448,576
-seeq_constraintdetection-0.0.4.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-seeq_constraintdetection-0.0.4.dist-info/top_level.txt,sha256=A8tWxHwd8hH2__1htF-LC8InFA4giQ1S3rsqii4tRSU,5
-seeq_constraintdetection-0.0.4.dist-info/RECORD,,
+seeq_constraintdetection-0.0.41.dist-info/LICENSE,sha256=UOZ1F5fFDe3XXvG4oNnkL1-Ecun7zpHzRxjp-XsMeAo,11324
+seeq_constraintdetection-0.0.41.dist-info/METADATA,sha256=HsPCx3o-2MmzeHzT7AT_ypfq_Y8XSzxsS7kCcFW1hiM,5580
+seeq_constraintdetection-0.0.41.dist-info/NOTICE,sha256=nGnOFYbt8mvVphIOBbCTDVGLEMEOrlDyXKCYzWIkWRM,566
+seeq_constraintdetection-0.0.41.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+seeq_constraintdetection-0.0.41.dist-info/top_level.txt,sha256=A8tWxHwd8hH2__1htF-LC8InFA4giQ1S3rsqii4tRSU,5
+seeq_constraintdetection-0.0.41.dist-info/RECORD,,
```

