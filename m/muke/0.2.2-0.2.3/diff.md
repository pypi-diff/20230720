# Comparing `tmp/muke-0.2.2-py3-none-any.whl.zip` & `tmp/muke-0.2.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,25 +1,25 @@
-Zip file size: 14604 bytes, number of entries: 23
--rw-r--r--  2.0 unx      844 b- defN 22-Dec-22 14:45 muke/Lines.py
--rw-r--r--  2.0 unx    11441 b- defN 22-Dec-22 14:45 muke/Muke.py
--rw-r--r--  2.0 unx        0 b- defN 22-Dec-22 14:45 muke/__init__.py
--rw-r--r--  2.0 unx     2320 b- defN 22-Dec-22 14:45 muke/__main__.py
--rw-r--r--  2.0 unx      330 b- defN 22-Dec-22 14:45 muke/detector/BaseDetector.py
--rw-r--r--  2.0 unx      392 b- defN 22-Dec-22 14:45 muke/detector/KeyPoint2.py
--rw-r--r--  2.0 unx      467 b- defN 22-Dec-22 14:45 muke/detector/MediaPipeFaceDetector.py
--rw-r--r--  2.0 unx      449 b- defN 22-Dec-22 14:45 muke/detector/MediaPipePoseDetector.py
--rw-r--r--  2.0 unx     1266 b- defN 22-Dec-22 14:45 muke/detector/MediaPiperBaseDetector.py
--rw-r--r--  2.0 unx        0 b- defN 22-Dec-22 14:45 muke/detector/__init__.py
--rw-r--r--  2.0 unx      195 b- defN 22-Dec-22 14:45 muke/generator/BaseGenerator.py
--rw-r--r--  2.0 unx      536 b- defN 22-Dec-22 14:45 muke/generator/Wrap3Generator.py
--rw-r--r--  2.0 unx        0 b- defN 22-Dec-22 14:45 muke/generator/__init__.py
--rw-r--r--  2.0 unx      296 b- defN 22-Dec-22 14:45 muke/model/DetectionView.py
--rw-r--r--  2.0 unx      730 b- defN 22-Dec-22 14:45 muke/model/KeyPoint3.py
--rw-r--r--  2.0 unx     2535 b- defN 22-Dec-22 14:45 muke/model/MukeConfiguration.py
--rw-r--r--  2.0 unx      394 b- defN 22-Dec-22 14:45 muke/model/__init__.py
--rw-r--r--  2.0 unx     1074 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/LICENSE
--rw-r--r--  2.0 unx     5598 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       45 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        5 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1857 b- defN 22-Dec-22 14:45 muke-0.2.2.dist-info/RECORD
-23 files, 30866 bytes uncompressed, 11584 bytes compressed:  62.5%
+Zip file size: 15511 bytes, number of entries: 23
+-rw-r--r--  2.0 unx      844 b- defN 23-Jul-20 13:09 muke/Lines.py
+-rw-r--r--  2.0 unx    12452 b- defN 23-Jul-20 13:09 muke/Muke.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 13:09 muke/__init__.py
+-rw-r--r--  2.0 unx     2571 b- defN 23-Jul-20 13:09 muke/__main__.py
+-rw-r--r--  2.0 unx      330 b- defN 23-Jul-20 13:09 muke/detector/BaseDetector.py
+-rw-r--r--  2.0 unx      392 b- defN 23-Jul-20 13:09 muke/detector/KeyPoint2.py
+-rw-r--r--  2.0 unx      613 b- defN 23-Jul-20 13:09 muke/detector/MediaPipeFaceDetector.py
+-rw-r--r--  2.0 unx      588 b- defN 23-Jul-20 13:09 muke/detector/MediaPipePoseDetector.py
+-rw-r--r--  2.0 unx     1266 b- defN 23-Jul-20 13:09 muke/detector/MediaPiperBaseDetector.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 13:09 muke/detector/__init__.py
+-rw-r--r--  2.0 unx      195 b- defN 23-Jul-20 13:09 muke/generator/BaseGenerator.py
+-rw-r--r--  2.0 unx      536 b- defN 23-Jul-20 13:09 muke/generator/Wrap3Generator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-20 13:09 muke/generator/__init__.py
+-rw-r--r--  2.0 unx      296 b- defN 23-Jul-20 13:09 muke/model/DetectionView.py
+-rw-r--r--  2.0 unx      730 b- defN 23-Jul-20 13:09 muke/model/KeyPoint3.py
+-rw-r--r--  2.0 unx     2535 b- defN 23-Jul-20 13:09 muke/model/MukeConfiguration.py
+-rw-r--r--  2.0 unx      394 b- defN 23-Jul-20 13:09 muke/model/__init__.py
+-rw-r--r--  2.0 unx     1075 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6847 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       45 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        5 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1857 b- defN 23-Jul-20 13:09 muke-0.2.3.dist-info/RECORD
+23 files, 33663 bytes uncompressed, 12491 bytes compressed:  62.9%
```

## zipnote {}

```diff
@@ -45,26 +45,26 @@
 
 Filename: muke/model/MukeConfiguration.py
 Comment: 
 
 Filename: muke/model/__init__.py
 Comment: 
 
-Filename: muke-0.2.2.dist-info/LICENSE
+Filename: muke-0.2.3.dist-info/LICENSE
 Comment: 
 
-Filename: muke-0.2.2.dist-info/METADATA
+Filename: muke-0.2.3.dist-info/METADATA
 Comment: 
 
-Filename: muke-0.2.2.dist-info/WHEEL
+Filename: muke-0.2.3.dist-info/WHEEL
 Comment: 
 
-Filename: muke-0.2.2.dist-info/entry_points.txt
+Filename: muke-0.2.3.dist-info/entry_points.txt
 Comment: 
 
-Filename: muke-0.2.2.dist-info/top_level.txt
+Filename: muke-0.2.3.dist-info/top_level.txt
 Comment: 
 
-Filename: muke-0.2.2.dist-info/RECORD
+Filename: muke-0.2.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## muke/Muke.py

```diff
@@ -1,50 +1,61 @@
 import logging
-from typing import List
+from typing import List, Sequence, Optional
 
 import cv2
 import numpy as np
 import open3d as o3d
 
 from muke.Lines import Lines
 from muke.detector.BaseDetector import BaseDetector
 from muke.detector.KeyPoint2 import KeyPoint2
 from muke.model.DetectionView import DetectionView
 from muke.model.KeyPoint3 import KeyPoint3
 
 from scipy.spatial import distance
 
 
-class Muke(object):
+class Muke:
     def __init__(self, detector: BaseDetector, resolution: int = 512, display=False, debug=False):
-        self.detector = detector
+        self.detector: BaseDetector = detector
 
-        self.display = display
-        self.debug = debug
+        self.display: bool = display
+        self.debug: bool = debug
 
-        self.width = resolution
-        self.height = resolution
-        self.pixel_density = 1.0
+        self.width: int = resolution
+        self.height: int = resolution
+        self.pixel_density: float = 1.0
 
-        self.ray_size = 5
+        self.ray_size: float = 5
 
-        self.camera_zoom = 0.55
-        self.camera_fov = -90  # by default orthographic
+        self.camera_zoom: float = 0.55
+        self.camera_fov: float = -90  # by default orthographic
 
-        self.background_color = [255, 255, 255]
+        self.background_color: Sequence[int] = [255, 255, 255]
+
+        self.mesh_shade_option: Optional[o3d.visualization.MeshShadeOption] = None
+        self.mesh_color_option: Optional[o3d.visualization.MeshColorOption] = None
+        self.light_on: bool = True
 
     def __enter__(self):
         self.detector.setup()
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self.detector.release()
 
-    def detect_file(self, mesh_path: str, views: List[DetectionView], post_processing: bool = True) -> List[KeyPoint3]:
-        mesh = o3d.io.read_triangle_mesh(mesh_path, enable_post_processing=post_processing)
+    def detect_file(self, mesh_path: str, views: List[DetectionView],
+                    post_processing: bool = True) -> List[KeyPoint3]:
+        mesh: o3d.geometry.TriangleMesh = o3d.io.read_triangle_mesh(mesh_path, enable_post_processing=post_processing)
+
+        if post_processing:
+            # check if mesh has colors or triangle normals -> otherwise calculate them
+            if not mesh.has_triangle_normals() and not mesh.has_vertex_colors() and not mesh.has_textures():
+                mesh.compute_triangle_normals()
+
         return self.detect(mesh, views)
 
     def detect(self, mesh: o3d.geometry.TriangleMesh, views: List[DetectionView]) -> List[KeyPoint3]:
         # setup scene
         vis = o3d.visualization.VisualizerWithVertexSelection()
         vis.create_window(width=self.width, height=self.height, visible=self.display)
         vis.add_geometry(mesh, reset_bounding_box=True)
@@ -53,14 +64,22 @@
         ctr.change_field_of_view(self.camera_fov)
         ctr.set_zoom(self.camera_zoom)
 
         opt: o3d.visualization.RenderOption = vis.get_render_option()
         opt.background_color = np.asarray(self.background_color)
         opt.show_coordinate_frame = False
 
+        if self.mesh_shade_option is not None:
+            opt.mesh_shade_option = self.mesh_shade_option
+
+        if self.mesh_color_option is not None:
+            opt.mesh_color_option = self.mesh_color_option
+
+        opt.light_on = self.light_on
+
         # detect keypoints
         detections = {}
         view_stack = views[::-1]
 
         def render(v):
             if len(view_stack) == 0:
                 v.close()
@@ -138,32 +157,34 @@
         if view.keypoints is not None:
             keypoints = list(filter(lambda kp: kp.index in view.keypoints, keypoints))
 
         # annotate if debug is on
         if self.debug:
             preview_image = image_np.copy()
             preview_image = cv2.cvtColor(preview_image, cv2.COLOR_RGB2BGR)
-            self._annotate_keypoints_2d(preview_image, keypoints)
+            self._annotate_keypoints_2d(preview_image, keypoints, weight=2)
             cv2.imshow(f"{view.name}: 2D Key Points", preview_image)
             cv2.waitKey(0)
             cv2.destroyAllWindows()
 
         # raycast from camera
         vertices = np.asarray(mesh.vertices)
         result = []
+
         for kp in keypoints:
             x, y = self._get_transformed_coordinates(kp)
             half_ray_size = self.ray_size * 0.5
 
             picked_vertices = vis.pick_points(x, y, self.ray_size, self.ray_size)
             # todo: replace this with an actual position estimation (raycasting) instead of a vertex
             picked_vertices = vis.pick_points(x - half_ray_size, y - half_ray_size, self.ray_size, self.ray_size)
 
             if self.debug:
-                vis.add_picked_points(picked_vertices)
+                pass
+                # vis.add_picked_points(picked_vertices)
 
             picked_vertices = [picked_vertices[i] for i in range(len(picked_vertices))]
 
             if len(picked_vertices) == 0:
                 continue
 
             positions = np.stack([vertices[vi] for vi in picked_vertices])
@@ -278,12 +299,15 @@
             marker: o3d.geometry.TriangleMesh = o3d.geometry.TriangleMesh.create_sphere(radius=box_size, resolution=5)
             marker.translate(np.array([kp.x, kp.y, kp.z]))
             marker.paint_uniform_color(np.array(list(color)) / 255.0)
             meshes.append(marker)
 
         o3d.visualization.draw_geometries(meshes, title, width=self.width, height=self.height)
 
-    def _annotate_keypoints_2d(self, image: np.ndarray, keypoints: [KeyPoint2], size: int = 15, color=(0, 255, 0)):
+    def _annotate_keypoints_2d(self, image: np.ndarray, keypoints: [KeyPoint2],
+                               size: int = 15, color=(20, 255, 255), weight: int = 1):
+
+        hs = int(round(size * 0.5))
         for kp in keypoints:
             x, y = self._get_transformed_coordinates(kp)
-            cv2.drawMarker(image, (x, y), color, cv2.MARKER_CROSS, size, 1)
-            cv2.putText(image, f"{kp.index}", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)
+            cv2.drawMarker(image, (x, y), color, cv2.MARKER_TILTED_CROSS, size, weight)
+            cv2.putText(image, f"{kp.index}", (x + hs, y + hs), cv2.FONT_HERSHEY_PLAIN, 1, color, weight, cv2.LINE_AA)
```

## muke/__main__.py

```diff
@@ -16,17 +16,19 @@
     parser.add_argument("--detector", default=detection_methods[0], choices=detection_methods,
                         help="Detection method for 2d keypoint detection (default: %s)." % detection_methods[0])
     parser.add_argument("--resolution", default=MukeDefaultResolution, type=int,
                         help="Render resolution for each view pass (default: %d)." % MukeDefaultResolution)
     parser.add_argument("--generator", default=generator_methods[0], choices=generator_methods,
                         help="Generator methods for output generation (default: %s)." % generator_methods[0])
     parser.add_argument("--config", required=False, help="Path to the configuration JSON file.")
-    parser.add_argument("--display", action='store_true',
+    parser.add_argument("--load-raw", action="store_true",
+                        help="Load mesh raw without post-processing (default: False)")
+    parser.add_argument("--display", action="store_true",
                         help="Shows result rendering with keypoints (default: False)")
-    parser.add_argument("--debug", action='store_true',
+    parser.add_argument("--debug", action="store_true",
                         help="Shows debug frames and information (default: False)")
 
     args = parser.parse_args()
     return args
 
 
 def main():
@@ -45,13 +47,15 @@
     output = config.generator
 
     with Muke(config.detector,
               resolution=config.resolution,
               display=args.display,
               debug=args.debug) as muke:
 
-        results = muke.detect_file(args.input, views=config.views)
+        results = muke.detect_file(args.input,
+                                   post_processing=not args.load_raw,
+                                   views=config.views)
         output.generate(args.input, results)
 
 
 if __name__ == "__main__":
     main()
```

## muke/detector/MediaPipeFaceDetector.py

```diff
@@ -8,8 +8,11 @@
 
 
 class MediaPipeFaceDetector(MediaPipeBaseDetector):
     def create_model(self) -> SolutionBase:
         return mp_model.FaceMesh(static_image_mode=True)
 
     def get_landmarks(self, results):
+        if results.multi_face_landmarks is None:
+            raise Exception("No faces detected on rendering. Please check the render options.")
+
         return results.multi_face_landmarks[0]
```

## muke/detector/MediaPipePoseDetector.py

```diff
@@ -8,8 +8,11 @@
 
 
 class MediaPipePoseDetector(MediaPipeBaseDetector):
     def create_model(self) -> SolutionBase:
         return mp_model.Pose(static_image_mode=True)
 
     def get_landmarks(self, results):
+        if results.pose_landmarks is None:
+            raise Exception("No pose detected on rendering. Please check the render options.")
+
         return results.pose_landmarks
```

## Comparing `muke-0.2.2.dist-info/LICENSE` & `muke-0.2.3.dist-info/LICENSE`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 MIT License
 
-Copyright (c) 2021 Florian Bruggisser
+Copyright (c) 2023 Florian Bruggisser
 
 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:
@@ -14,8 +14,8 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
+SOFTWARE.
```

## Comparing `muke-0.2.2.dist-info/METADATA` & `muke-0.2.3.dist-info/METADATA`

 * *Files 14% similar despite different names*

```diff
@@ -1,46 +1,53 @@
 Metadata-Version: 2.1
 Name: muke
-Version: 0.2.2
-Summary: A simple approach to detect 3d keypoints by using 2d estimation methods and multiview rendering.
+Version: 0.2.3
+Summary: A simple approach to 3D keypoint detection using 2D estimation methods and multiview rendering.
 Home-page: https://github.com/cansik/multiview-3d-keypoint-detection
 Author: Florian Bruggisser
 Author-email: github@broox.ch
 License: MIT License
 Platform: UNKNOWN
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: wheel
 Requires-Dist: numpy
 Requires-Dist: open3d (>=0.16.0)
 Requires-Dist: opencv-python
 Requires-Dist: tqdm
 Requires-Dist: scipy
-Requires-Dist: mediapipe ; platform_system != "Darwin" or platform_machine != "arm64"
-Requires-Dist: mediapipe-silicon ; platform_system == "Darwin" and platform_machine == "arm64"
+Requires-Dist: mediapipe
 
 # Multiview 3D Keypoint Detection (Muke) [![PyPI](https://img.shields.io/pypi/v/muke)](https://pypi.org/project/muke/)
-A simple approach to detect 3d keypoints by using 2d estimation methods and multiview rendering. The idea is based on the blender project for [automatic keypoint retopology](https://github.com/cansik/auto-keypoint-retopology).
-Basically the 3d model is rendered from various angles (views) and a 2d key-point detection is applied. For each detected keypoint a ray-cast is performed to detect the intersection point with the mesh surface. In the end all intersection of the different views are combined to calculate the actual 3d position of the keypoint inside the mesh. It is possible to define view dependent keypoint indices to extract only the ones that are visible in the current rendering. Muke return a list of 3d keypoints containing the position as well as the closest vertex index.
+A simple approach to 3D keypoint detection using 2D estimation methods and multiview rendering, based on the blender project for [automatic keypoint retopology](https://github.com/cansik/auto-keypoint-retopology).
+
+Basically, the 3D model is rendered from different angles (views) and a 2D keypoint detection is performed. For each detected keypoint, a ray-cast is performed to determine the intersection point with the mesh surface. In the end, all intersection points of the different views are combined to calculate the current 3D position of the keypoint within the mesh. It is possible to define view-dependent keypoint indices to extract only the points that are visible in the current rendering. Muke returns a list of 3D keypoints containing both the position and the nearest vertex index.
 
 ![Visualisation](documentation/visualisation.png)
+
 *Muke Process*
 
+Direct 3D keypoint recognition using mesh data would be more accurate, but it is still difficult to train 3D models or find already trained weights for them. By using 2D recognition alone, it is possible to use the entire zoo of keypoint image recognition models. Muke comes with a built-in [MediaPipe face](https://google.github.io/mediapipe/solutions/face_mesh.html) and [pose](https://google.github.io/mediapipe/solutions/pose.html) detector, but can be extended with any other 2D keypoint detection framework.
+
+![Head Example](documentation/head.png)
+
+*3D Facial Landmark Estimation (Human Head by [VistaPrime](https://sketchfab.com/3d-models/human-head-f46d952886ae4a8c8851341b810bba43) [CC Attribution](https://creativecommons.org/licenses/by/4.0/))*
+
 The project was originally implemented to have a simple and fast solution for 3D keypoints detection for retopology purposes. However, it can also be used for any other application where 3D keypoints are needed, such as rigging, animation, etc.
 
 ### Installation
 
 To install the package use the following pip command:
 
 ```bash
 pip install muke
 ```
 
 ### Usage
-Muke can be used as a command line tool to extract the keypoints in a specific format (f.e. [Wrap3](https://www.russian3dscanner.com/)). For that a configuration has to be created which defines the detection parameters as well as the rendering views.
+Muke can be used as a command line tool to extract the keypoints in a specific format (e.g. [Wrap3](https://www.russian3dscanner.com/)). For that a configuration has to be created which defines the detection parameters as well as the rendering views.
 
 #### Configuration
 
 Example configuration:
 
 ```json
 {
@@ -69,47 +76,52 @@
   "start": 10,
   "end": 15,
   "skip": [13, 14]
 }
 ```
 
 #### Demo
+Quickly try out Muke by using the following commands.
 
 ```bash
 python -m muke assets/person.ply --display --resolution 1024
 ```
 
 ```bash
-python -m muke temp/AlexedWrapped.obj --display --resolution 1024 --detector media-pipe-face
+python -m muke assets/human_head.obj --display --resolution 1024 --detector media-pipe-face
 ```
 
 ```bash
-python -m muke temp/AlexedWrapped.obj --display --config config/media-pipe-face.json
+python -m muke assets/human_head.obj --config config/media-pipe-face.json --display
 ```
 
 #### Help
 
 ```bash
-usage: muke [-h] [--detector {media-pipe-pose,media-pipe-face}] [--resolution RESOLUTION] [--generator {wrap3}]
-            [--config CONFIG] [--display] [--debug]
+usage: muke [-h] [--detector {media-pipe-pose,media-pipe-face}]
+            [--resolution RESOLUTION] [--generator {wrap3}] [--config CONFIG]
+            [--load-raw] [--display] [--debug]
             input
 
 Detects keypoint locations in a 3d model.
 
 positional arguments:
   input                 Input mesh to process.
 
 optional arguments:
   -h, --help            show this help message and exit
   --detector {media-pipe-pose,media-pipe-face}
-                        Detection method for 2d keypoint detection (default: media-pipe-pose).
+                        Detection method for 2d keypoint detection (default:
+                        media-pipe-pose).
   --resolution RESOLUTION
                         Render resolution for each view pass (default: 512).
-  --generator {wrap3}   Generator methods for output generation (default: wrap3).
+  --generator {wrap3}   Generator methods for output generation (default:
+                        wrap3).
   --config CONFIG       Path to the configuration JSON file.
+  --load-raw            Load mesh raw without post-processing (default: False)
   --display             Shows result rendering with keypoints (default: False)
   --debug               Shows debug frames and information (default: False)
 ```
 
 ### Library
 It is also possible to use Muke as a library to detect keypoints on an existing 3d mesh.
 
@@ -159,11 +171,14 @@
         pass
 
     def release(self):
         # todo: clean up allocated resources
         pass
 ```
 
+### Renderer
+The current version uses [Open3D](https://github.com/isl-org/Open3D) for rendering and raycasting. Initially, [trimesh](https://github.com/mikedh/trimesh) was used, which is archived in the [trimesh-renderer branch](https://github.com/cansik/multiview-3d-keypoint-detection/tree/trimesh-renderer). In the future it would be interesting to use [pygfx](https://github.com/pygfx/pygfx) as a lightweight alternative to Open3D.
+
 ### About
-MIT License - Copyright (c) 2022 Florian Bruggisser
+MIT License - Copyright (c) 2023 Florian Bruggisser
```

